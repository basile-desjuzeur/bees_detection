{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> <u>**Détections** </u></center>\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Chargement des données"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. Vériﬁcation des données\n",
    "\n",
    "On vérifie que le transfert entre le disque dur et le disque local s'est bien passé."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define variables\n",
    "\n",
    "path_to_hard_drive = '/media/basile/One Touch/Disque dur Axel pour Basile/BD_71'\n",
    "path_to_jsons = '/data_bees_detection/BD_71_Annotations/JSON'\n",
    "path_to_images = '/workspaces/projet_bees_detection_basile/data_bees_detection/BD_71'\n",
    "path_to_output = '/workspaces/projet_bees_detection_basile/bees_detection/datafiles/yolo/inputs'\n",
    "\n",
    "# define the taxon to detect\n",
    "taxon_detection = 'Anthophila'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "111983\n"
     ]
    }
   ],
   "source": [
    "! find $path_to_images -type f | wc -l"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En lancant la commande : \n",
    "\n",
    "! find \"$path_to_hard_drive\" -type f | wc -l\n",
    "\n",
    "Depuis un terminal sur le disque dur on obtient aussi 111983."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. Edition d'un csv récapitulatif"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "csv avec seulement les chemins des images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "! find $path_to_images -type f >> $path_to_output/BD_71.csv"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "csv issus des fichiers json avec le format suivant :\n",
    "\n",
    "* image_path\n",
    "* xmin\n",
    "* ymin\n",
    "* xmax\n",
    "* ymax\n",
    "* label\n",
    "* width\n",
    "* height\n",
    "\n",
    "Edité avec le script [suivant](../src/yolo/utils_for_datafiles/json_to_csv.py).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run /workspaces/projet_bees_detection_basile/bees_detection/src/yolo/utils_for_datafiles/json_to_csv.py  -j $path_to_jsons -i $path_to_images -t $taxon_detection -o $path_to_output"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visiblement certaines images sont manquantes (référencées dans BD_71_missing_old.csv) : les images sont corrompues ou manquantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# remplacer les images corrompues par des images saines\n",
    "path_missing = '/workspaces/projet_bees_detection_basile/bees_detection/datafiles/yolo/inputs/BD_71_missing.csv'\n",
    "df_missing = pd.read_csv(path_missing, header=None,skiprows=1)\n",
    "\n",
    "path_saines = '/workspaces/projet_bees_detection_basile/data_bees_detection/corrompues_bd71'\n",
    "\n",
    "df_missing['img_name'] = df_missing[0].apply(lambda x: x.split('/')[-1])\n",
    "df_missing['new_path'] = df_missing['img_name'].apply(lambda x: path_saines + '/' + x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>img_name</th>\n",
       "      <th>new_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/workspaces/projet_bees_detection_basile/data_...</td>\n",
       "      <td>Bombus pascuorum96207.jpeg</td>\n",
       "      <td>/workspaces/projet_bees_detection_basile/data_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/workspaces/projet_bees_detection_basile/data_...</td>\n",
       "      <td>_dsc0461.jpg</td>\n",
       "      <td>/workspaces/projet_bees_detection_basile/data_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/workspaces/projet_bees_detection_basile/data_...</td>\n",
       "      <td>DH9_1898-4.jpg</td>\n",
       "      <td>/workspaces/projet_bees_detection_basile/data_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/workspaces/projet_bees_detection_basile/data_...</td>\n",
       "      <td>DH9_1916-2.jpg</td>\n",
       "      <td>/workspaces/projet_bees_detection_basile/data_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/workspaces/projet_bees_detection_basile/data_...</td>\n",
       "      <td>DH9_1899-2.jpg</td>\n",
       "      <td>/workspaces/projet_bees_detection_basile/data_...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0  \\\n",
       "0  /workspaces/projet_bees_detection_basile/data_...   \n",
       "1  /workspaces/projet_bees_detection_basile/data_...   \n",
       "2  /workspaces/projet_bees_detection_basile/data_...   \n",
       "3  /workspaces/projet_bees_detection_basile/data_...   \n",
       "4  /workspaces/projet_bees_detection_basile/data_...   \n",
       "\n",
       "                     img_name  \\\n",
       "0  Bombus pascuorum96207.jpeg   \n",
       "1                _dsc0461.jpg   \n",
       "2              DH9_1898-4.jpg   \n",
       "3              DH9_1916-2.jpg   \n",
       "4              DH9_1899-2.jpg   \n",
       "\n",
       "                                            new_path  \n",
       "0  /workspaces/projet_bees_detection_basile/data_...  \n",
       "1  /workspaces/projet_bees_detection_basile/data_...  \n",
       "2  /workspaces/projet_bees_detection_basile/data_...  \n",
       "3  /workspaces/projet_bees_detection_basile/data_...  \n",
       "4  /workspaces/projet_bees_detection_basile/data_...  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_missing.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cp: cannot stat '/workspaces/projet_bees_detection_basile/data_bees_detection/corrompues_bd71/Bombus pascuorum96207.jpeg': No such file or directory\n",
      "cp: cannot stat '/workspaces/projet_bees_detection_basile/data_bees_detection/corrompues_bd71/_dsc0461.jpg': No such file or directory\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "for index, row in df_missing.iterrows():\n",
    "    \n",
    "    # copy the image from the saines folder to the BD_71 folder\n",
    "    os.system('cp \"' + row['new_path'] + '\" \"' + row[0] + '\"')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vériﬁcation des images manquantes :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run /workspaces/projet_bees_detection_basile/bees_detection/src/yolo/utils_for_datafiles/json_to_csv.py  -j $path_to_jsons -i $path_to_images -t $taxon_detection -o $path_to_output"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parenthèse : pourquoi il y a des images manquantes ?\n",
    "\n",
    "i.e. pourquoi 111983 images dans BD_71 et seulement 24802 dans BD_71_input.csv ?\n",
    "\n",
    "Car on ne prend que les images qui ont été vérifiées. \n",
    "\n",
    "Cf. la démonstration dans le notebook [suivant](../Notebooks/check_json.ipynb)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3. Split des données en train / test / validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_dataset = '/workspaces/projet_bees_detection_basile/bees_detection/datafiles/yolo/inputs/BD_71_input.csv'\n",
    "\n",
    "df_dataset = pd.read_csv(path_to_dataset, header=None)\n",
    "\n",
    "# shuffle the dataset\n",
    "df_dataset = df_dataset.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "# split the dataset into train, test and validation sets\n",
    "# 80% train, 10% test, 10% validation\n",
    "\n",
    "train_size = int(df_dataset.shape[0] * 0.8)\n",
    "test_size = int(df_dataset.shape[0] * 0.1)\n",
    "val_size = int(df_dataset.shape[0] * 0.1)\n",
    "\n",
    "df_train = df_dataset.iloc[:train_size]\n",
    "df_test = df_dataset.iloc[train_size:train_size+test_size]\n",
    "df_val = df_dataset.iloc[train_size+test_size:]\n",
    "\n",
    "# save the datasets\n",
    "path_to_train = '/workspaces/projet_bees_detection_basile/bees_detection/datafiles/yolo/inputs/BD_71_train.csv'\n",
    "path_to_test = '/workspaces/projet_bees_detection_basile/bees_detection/datafiles/yolo/inputs/BD_71_test.csv'\n",
    "path_to_val = '/workspaces/projet_bees_detection_basile/bees_detection/datafiles/yolo/inputs/BD_71_val.csv'\n",
    "\n",
    "df_train.to_csv(path_to_train, header=None, index=False)\n",
    "df_test.to_csv(path_to_test, header=None, index=False)\n",
    "df_val.to_csv(path_to_val, header=None, index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Entraînement du modèle"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Générer des anchor box\n",
    "\n",
    "On pourra utiliser ce [template](../datafiles/yolo/configs/benchmark_configs/example.json) de fichier de conﬁguration pour commencer.\n",
    "\n",
    "Le script [suivant](../src/yolo/utils/gen_anchors.py) permet de générer des anchor box."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = '/workspaces/projet_bees_detection_basile/bees_detection/datafiles/yolo/configs/benchmark_configs/example.json'\n",
    "nb_anchors = 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/19841 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19841/19841 [00:00<00:00, 189654.77it/s]\n",
      "2023-07-05 21:30:14.222848: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:266] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2023-07-05 21:30:14.222877: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:168] retrieving CUDA diagnostic information for host: f65f42a282a8\n",
      "2023-07-05 21:30:14.222883: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:175] hostname: f65f42a282a8\n",
      "2023-07-05 21:30:14.222982: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:199] libcuda reported version is: NOT_FOUND: was unable to find libcuda.so DSO loaded into this program\n",
      "2023-07-05 21:30:14.223073: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:203] kernel reported version is: 510.108.3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature extractor output shape: (7, 7)\n",
      "grid size: 32.0 x 32.0\n",
      "iteration 1: dists = 53781.054326253776\n",
      "iteration 2: dists = 5689.58627195336\n",
      "iteration 3: dists = 981.375237331076\n",
      "iteration 4: dists = 489.63697201631794\n",
      "iteration 5: dists = 380.94913897540494\n",
      "iteration 6: dists = 330.63857840727735\n",
      "iteration 7: dists = 247.7071562017945\n",
      "iteration 8: dists = 227.56105462402465\n",
      "iteration 9: dists = 186.2180919749961\n",
      "iteration 10: dists = 168.30232192469404\n",
      "iteration 11: dists = 116.4734374365683\n",
      "iteration 12: dists = 101.77870792695333\n",
      "iteration 13: dists = 84.65858050382136\n",
      "iteration 14: dists = 83.10064015129528\n",
      "iteration 15: dists = 73.18377370377317\n",
      "iteration 16: dists = 43.71904567227098\n",
      "iteration 17: dists = 30.83243374718775\n",
      "iteration 18: dists = 30.9869460556548\n",
      "iteration 19: dists = 27.996159037650276\n",
      "iteration 20: dists = 21.35436263309002\n",
      "iteration 21: dists = 9.186860488539484\n",
      "iteration 22: dists = 5.62319127221101\n",
      "iteration 23: dists = 11.149817728351678\n",
      "iteration 24: dists = 11.355990110571787\n",
      "iteration 25: dists = 4.390014146181825\n",
      "iteration 26: dists = 5.098768847636346\n",
      "iteration 27: dists = 5.825525378881017\n",
      "iteration 28: dists = 4.30223924236917\n",
      "iteration 29: dists = 4.240540082391459\n",
      "iteration 30: dists = 5.985479179928746\n",
      "iteration 31: dists = 7.964732852398941\n",
      "iteration 32: dists = 5.482403325942182\n",
      "iteration 33: dists = 4.56569014415443\n",
      "\n",
      "average IOU for 5 anchors: 0.76\n",
      "anchors: [7.49546,7.70589, 12.93272,13.18093, 15.36888,22.14079, 22.03487,17.36667, 25.14208,25.92849]\n"
     ]
    }
   ],
   "source": [
    "%run /workspaces/projet_bees_detection_basile/bees_detection/src/yolo/utils/gen_anchors.py -c $config_path -a $nb_anchors"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut reporter les anchor box dans le fichier de conﬁguration."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. Edition du fichier de configuration\n",
    "\n",
    "Ajuster au besoin les paramètres du fichier de conﬁguration."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3. Entraînement du modèle\n",
    "\n",
    "Voir [script](../src/yolo/train.py)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = '/workspaces/projet_bees_detection_basile/bees_detection/datafiles/yolo/configs/benchmark_configs/example.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/19841 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19841/19841 [00:00<00:00, 235145.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " \n",
      "Parsing BD_71_val.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2482/2482 [00:00<00:00, 142458.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"MobileNetv2_backend\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_7 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " mobilenetv2_1.00_224 (Funct  (None, 7, 7, 1280)       2257984   \n",
      " ional)                                                          \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,257,984\n",
      "Trainable params: 2,223,872\n",
      "Non-trainable params: 34,112\n",
      "_________________________________________________________________\n",
      "None\n",
      "(7, 7)\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_6 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " MobileNetv2_backend (Functi  (None, 7, 7, 1280)       2257984   \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " Detection_layer (Conv2D)    (None, 7, 7, 30)          38430     \n",
      "                                                                 \n",
      " YOLO_output (Reshape)       (None, 7, 7, 5, 6)        0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,296,414\n",
      "Trainable params: 2,262,302\n",
      "Non-trainable params: 34,112\n",
      "_________________________________________________________________\n",
      "None\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_6 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " MobileNetv2_backend (Functi  (None, 7, 7, 1280)       2257984   \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " Detection_layer (Conv2D)    (None, 7, 7, 30)          38430     \n",
      "                                                                 \n",
      " YOLO_output (Reshape)       (None, 7, 7, 5, 6)        0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,296,414\n",
      "Trainable params: 2,262,302\n",
      "Non-trainable params: 34,112\n",
      "_________________________________________________________________\n",
      "Epoch 1/80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-05 21:39:01.809364: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  72/1192 [>.............................] - ETA: 9:23 - loss: 1038.5677"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m/workspaces/projet_bees_detection_basile/bees_detection/src/yolo/train.py:126\u001b[0m\n\u001b[1;32m    124\u001b[0m     gpu_id \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mgetenv(\u001b[39m'\u001b[39m\u001b[39mCUDA_VISIBLE_DEVICES\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m0\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    125\u001b[0m     \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mdevice(\u001b[39m'\u001b[39m\u001b[39m/GPU:\u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m gpu_id):\n\u001b[0;32m--> 126\u001b[0m         _main_(_args)\n\u001b[1;32m    128\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mtf\u001b[39;00m\n\u001b[1;32m    129\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m \u001b[39mimport\u001b[39;00m keras\n",
      "File \u001b[0;32m/workspaces/projet_bees_detection_basile/bees_detection/src/yolo/train.py:97\u001b[0m, in \u001b[0;36m_main_\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m     91\u001b[0m     yolo\u001b[39m.\u001b[39mload_weights(config[\u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mpretrained_weights\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m     93\u001b[0m \u001b[39m###############################\u001b[39;00m\n\u001b[1;32m     94\u001b[0m \u001b[39m#   Start the training process\u001b[39;00m\n\u001b[1;32m     95\u001b[0m \u001b[39m###############################\u001b[39;00m\n\u001b[0;32m---> 97\u001b[0m yolo\u001b[39m.\u001b[39;49mtrain(train_imgs\u001b[39m=\u001b[39;49mtrain_imgs,\n\u001b[1;32m     98\u001b[0m            valid_imgs\u001b[39m=\u001b[39;49mvalid_imgs,\n\u001b[1;32m     99\u001b[0m            train_times\u001b[39m=\u001b[39;49mconfig[\u001b[39m'\u001b[39;49m\u001b[39mtrain\u001b[39;49m\u001b[39m'\u001b[39;49m][\u001b[39m'\u001b[39;49m\u001b[39mtrain_times\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    100\u001b[0m            nb_epochs\u001b[39m=\u001b[39;49mconfig[\u001b[39m'\u001b[39;49m\u001b[39mtrain\u001b[39;49m\u001b[39m'\u001b[39;49m][\u001b[39m'\u001b[39;49m\u001b[39mnb_epochs\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    101\u001b[0m            learning_rate\u001b[39m=\u001b[39;49mconfig[\u001b[39m'\u001b[39;49m\u001b[39mtrain\u001b[39;49m\u001b[39m'\u001b[39;49m][\u001b[39m'\u001b[39;49m\u001b[39mlearning_rate\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    102\u001b[0m            batch_size\u001b[39m=\u001b[39;49mconfig[\u001b[39m'\u001b[39;49m\u001b[39mtrain\u001b[39;49m\u001b[39m'\u001b[39;49m][\u001b[39m'\u001b[39;49m\u001b[39mbatch_size\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    103\u001b[0m            object_scale\u001b[39m=\u001b[39;49mconfig[\u001b[39m'\u001b[39;49m\u001b[39mtrain\u001b[39;49m\u001b[39m'\u001b[39;49m][\u001b[39m'\u001b[39;49m\u001b[39mobject_scale\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    104\u001b[0m            no_object_scale\u001b[39m=\u001b[39;49mconfig[\u001b[39m'\u001b[39;49m\u001b[39mtrain\u001b[39;49m\u001b[39m'\u001b[39;49m][\u001b[39m'\u001b[39;49m\u001b[39mno_object_scale\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    105\u001b[0m            coord_scale\u001b[39m=\u001b[39;49mconfig[\u001b[39m'\u001b[39;49m\u001b[39mtrain\u001b[39;49m\u001b[39m'\u001b[39;49m][\u001b[39m'\u001b[39;49m\u001b[39mcoord_scale\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    106\u001b[0m            class_scale\u001b[39m=\u001b[39;49mconfig[\u001b[39m'\u001b[39;49m\u001b[39mtrain\u001b[39;49m\u001b[39m'\u001b[39;49m][\u001b[39m'\u001b[39;49m\u001b[39mclass_scale\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    107\u001b[0m            saved_weights_name\u001b[39m=\u001b[39;49mconfig[\u001b[39m'\u001b[39;49m\u001b[39mtrain\u001b[39;49m\u001b[39m'\u001b[39;49m][\u001b[39m'\u001b[39;49m\u001b[39msaved_weights_name\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    108\u001b[0m            early_stop\u001b[39m=\u001b[39;49mconfig[\u001b[39m'\u001b[39;49m\u001b[39mtrain\u001b[39;49m\u001b[39m'\u001b[39;49m][\u001b[39m'\u001b[39;49m\u001b[39mearly_stop\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    109\u001b[0m            workers\u001b[39m=\u001b[39;49mconfig[\u001b[39m'\u001b[39;49m\u001b[39mtrain\u001b[39;49m\u001b[39m'\u001b[39;49m][\u001b[39m'\u001b[39;49m\u001b[39mworkers\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    110\u001b[0m            max_queue_size\u001b[39m=\u001b[39;49mconfig[\u001b[39m'\u001b[39;49m\u001b[39mtrain\u001b[39;49m\u001b[39m'\u001b[39;49m][\u001b[39m'\u001b[39;49m\u001b[39mmax_queue_size\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    111\u001b[0m            tb_logdir\u001b[39m=\u001b[39;49mconfig[\u001b[39m'\u001b[39;49m\u001b[39mtrain\u001b[39;49m\u001b[39m'\u001b[39;49m][\u001b[39m'\u001b[39;49m\u001b[39mtensorboard_log_dir\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    112\u001b[0m            optimizer_config\u001b[39m=\u001b[39;49mconfig[\u001b[39m'\u001b[39;49m\u001b[39mtrain\u001b[39;49m\u001b[39m'\u001b[39;49m][\u001b[39m'\u001b[39;49m\u001b[39moptimizer\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    113\u001b[0m            iou_threshold\u001b[39m=\u001b[39;49mconfig[\u001b[39m'\u001b[39;49m\u001b[39mvalid\u001b[39;49m\u001b[39m'\u001b[39;49m][\u001b[39m'\u001b[39;49m\u001b[39miou_threshold\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    114\u001b[0m            score_threshold\u001b[39m=\u001b[39;49mconfig[\u001b[39m'\u001b[39;49m\u001b[39mvalid\u001b[39;49m\u001b[39m'\u001b[39;49m][\u001b[39m'\u001b[39;49m\u001b[39mscore_threshold\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    115\u001b[0m            policy\u001b[39m=\u001b[39;49mconfig[\u001b[39m'\u001b[39;49m\u001b[39mtrain\u001b[39;49m\u001b[39m'\u001b[39;49m][\u001b[39m'\u001b[39;49m\u001b[39maugmentation\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    116\u001b[0m            mosaic\u001b[39m=\u001b[39;49mconfig[\u001b[39m'\u001b[39;49m\u001b[39mtrain\u001b[39;49m\u001b[39m'\u001b[39;49m][\u001b[39m'\u001b[39;49m\u001b[39mmosaic\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    117\u001b[0m            saved_pickles_path\u001b[39m=\u001b[39;49mconfig[\u001b[39m'\u001b[39;49m\u001b[39mdata\u001b[39;49m\u001b[39m'\u001b[39;49m][\u001b[39m'\u001b[39;49m\u001b[39msaved_pickles_path\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    118\u001b[0m            custom_callbacks\u001b[39m=\u001b[39;49m[],\n\u001b[1;32m    119\u001b[0m            sampling\u001b[39m=\u001b[39;49mconfig[\u001b[39m'\u001b[39;49m\u001b[39mtrain\u001b[39;49m\u001b[39m'\u001b[39;49m][\u001b[39m'\u001b[39;49m\u001b[39msampling\u001b[39;49m\u001b[39m'\u001b[39;49m])\n",
      "File \u001b[0;32m/workspaces/projet_bees_detection_basile/bees_detection/src/yolo/keras_yolov2/frontend.py:251\u001b[0m, in \u001b[0;36mYOLO.train\u001b[0;34m(self, train_imgs, valid_imgs, train_times, nb_epochs, learning_rate, batch_size, object_scale, no_object_scale, coord_scale, class_scale, policy, optimizer_config, mosaic, saved_pickles_path, saved_weights_name, workers, max_queue_size, early_stop, tb_logdir, iou_threshold, score_threshold, custom_callbacks, sampling)\u001b[0m\n\u001b[1;32m    245\u001b[0m     callbacks\u001b[39m.\u001b[39mappend(early_stop_cb)\n\u001b[1;32m    247\u001b[0m \u001b[39m#############################\u001b[39;00m\n\u001b[1;32m    248\u001b[0m \u001b[39m# Start the training process\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[39m#############################\u001b[39;00m\n\u001b[0;32m--> 251\u001b[0m history \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_model\u001b[39m.\u001b[39;49mfit(x\u001b[39m=\u001b[39;49mtrain_generator,\n\u001b[1;32m    252\u001b[0m                           steps_per_epoch\u001b[39m=\u001b[39;49m\u001b[39mlen\u001b[39;49m(train_generator) \u001b[39m*\u001b[39;49m train_times,\n\u001b[1;32m    253\u001b[0m                           epochs\u001b[39m=\u001b[39;49mnb_epochs,\n\u001b[1;32m    254\u001b[0m                           validation_data\u001b[39m=\u001b[39;49mvalid_generator,\n\u001b[1;32m    255\u001b[0m                           validation_steps\u001b[39m=\u001b[39;49m\u001b[39mlen\u001b[39;49m(valid_generator),\n\u001b[1;32m    256\u001b[0m                           callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[1;32m    257\u001b[0m                           workers\u001b[39m=\u001b[39;49mworkers,\n\u001b[1;32m    258\u001b[0m                           max_queue_size\u001b[39m=\u001b[39;49mmax_queue_size)\u001b[39m.\u001b[39mhistory\n\u001b[1;32m    262\u001b[0m \u001b[39m# Save history as pickle\u001b[39;00m\n\u001b[1;32m    263\u001b[0m saved_weights_file_name\u001b[39m=\u001b[39mroot\u001b[39m.\u001b[39msplit(os\u001b[39m.\u001b[39msep)[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n",
      "File \u001b[0;32m/workspaces/projet_bees_detection_basile/venv_bees_detection/lib/python3.8/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/workspaces/projet_bees_detection_basile/venv_bees_detection/lib/python3.8/site-packages/keras/engine/training.py:1685\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1677\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   1678\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1679\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1682\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m   1683\u001b[0m ):\n\u001b[1;32m   1684\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1685\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[1;32m   1686\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   1687\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m/workspaces/projet_bees_detection_basile/venv_bees_detection/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/workspaces/projet_bees_detection_basile/venv_bees_detection/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:894\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    891\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    893\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 894\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    896\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    897\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m/workspaces/projet_bees_detection_basile/venv_bees_detection/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:926\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    923\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    924\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    925\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 926\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_no_variable_creation_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    927\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variable_creation_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    928\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    929\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[1;32m    930\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[0;32m/workspaces/projet_bees_detection_basile/venv_bees_detection/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:143\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m    141\u001b[0m   (concrete_function,\n\u001b[1;32m    142\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m--> 143\u001b[0m \u001b[39mreturn\u001b[39;00m concrete_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[1;32m    144\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mconcrete_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[0;32m/workspaces/projet_bees_detection_basile/venv_bees_detection/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1757\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1753\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1754\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1755\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1756\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1757\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[1;32m   1758\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[1;32m   1759\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1760\u001b[0m     args,\n\u001b[1;32m   1761\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1762\u001b[0m     executing_eagerly)\n\u001b[1;32m   1763\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[0;32m/workspaces/projet_bees_detection_basile/venv_bees_detection/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:381\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    379\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[1;32m    380\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 381\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m    382\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[1;32m    383\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[1;32m    384\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m    385\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m    386\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[1;32m    387\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    388\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    389\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[1;32m    390\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    393\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[1;32m    394\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m/workspaces/projet_bees_detection_basile/venv_bees_detection/lib/python3.8/site-packages/tensorflow/python/eager/execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 52\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[1;32m     53\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     55\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%run ../src/yolo/train.py -c $config_path"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Evaluation du modèle\n",
    "\n",
    "Avec ce [script](../src/yolo/evaluate.py)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = '../datafiles/yolo/configs/benchmark_configs/example.json'\n",
    "weights_path = '../datafiles/yolo/saved_weights/Best_model_bestLoss.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../src/yolo/evaluate.py -c $config_path -w $weights_path"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "    <strong> Pour les poids et les configurations ci-dessus, on obtient ces résultats </strong>\n",
    "  <br>\n",
    "\n",
    "  <img src=\"../datafiles/imgs_for_readme/results_yolo.png\" alt=\"résultats\" />\n",
    "</p>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Pipeline prédictions\n",
    "\n",
    "Avec ce [script](../src/yolo/predict.py).\n",
    "\n",
    "Qui prend les arguments suivants :\n",
    "\n",
    "* -c : chemin vers le fichier de configuration\n",
    "* -w : chemin vers les poids du modèle\n",
    "* -i : chemin vers le dossier d'images, la vidéo ou le csv contenant les chemins des images à prédire\n",
    "* -o : mode de sortie : \"image\" ou \"csv_input\"\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On lancerait par exemple :\n",
    "\n",
    "```bash\n",
    "python predict.py -c ../datafiles/yolo/configs/benchmark_configs/example.json -w ../datafiles/yolo/weights/benchmark_weights/example.h5 -i ../datafiles/yolo/images/ -o csv_input\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_bees_detection",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
