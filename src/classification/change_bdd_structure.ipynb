{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CHANGE BDD STRUCTURE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import shutil\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_bdd = \"/home/basile/Documents/projet_bees_detection_basile/data_bees_detection/whole_dataset_cropped_with_cleaned_structure\"\n",
    "path_to_csv = \"/home/basile/Documents/projet_bees_detection_basile/bees_detection/src/datafiles/final_datafiles/dataset_yolo_cropped_with_real_labels.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create all the folders for the new structure\n",
    "\n",
    "if not os.path.exists(path_to_bdd):\n",
    "    os.mkdir(path_to_bdd)       \n",
    "\n",
    "df = pd.read_csv(path_to_csv)\n",
    "species = df[\"Real labels\"].unique()\n",
    "\n",
    "for specie in species:\n",
    "\n",
    "    path = os.path.join(path_to_bdd, specie)\n",
    "\n",
    "    if not os.path.exists(path):\n",
    "        os.mkdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy all the images in the right folder\n",
    "# the name of the image is the concatenation of the path and the name of the image\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "\n",
    "    \n",
    "    image_path = row[\"Paths\"]\n",
    "    real_label = row[\"Real labels\"]\n",
    "    image_name = \"_\".join(row[\"Paths\"].split(\"/\")[6:])\n",
    "\n",
    "    shutil.copy(os.path.join(image_path), os.path.join(path_to_bdd, real_label, image_name))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the new dataset in a csv file\n",
    "\n",
    "df = pd.DataFrame(columns=[\"Paths\", \"Labels\"])\n",
    "\n",
    "\n",
    "for specie in species:\n",
    "\n",
    "    path = os.path.join(path_to_bdd, specie)\n",
    "\n",
    "    temp = pd.DataFrame(columns=[\"Paths\", \"Labels\"])\n",
    "    temp[\"Paths\"] = [os.path.join(path, image) for image in os.listdir(path)]\n",
    "    temp[\"Labels\"] = specie\n",
    "\n",
    "    df = pd.concat([df, temp])\n",
    "\n",
    "df.to_csv(\"/home/basile/Documents/projet_bees_detection_basile/bees_detection/src/datafiles/final_datafiles/dataset_yolo_cropped_with_cleaned_structure.csv\", index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GEN TRAIN TEST VAL\n",
    "\n",
    "To start with, we'll create a simple dataset\n",
    "- only images labelled at species level\n",
    "- only species with more than a specified nb of pictures\n",
    "- no hierarchy between databases"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1/ Filter dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_dataset(only_species=True, min_images=None,hierarchy=False,df_dataset=None):\n",
    "    \"\"\"\n",
    "    Filter the dataset according to specified criteria. \n",
    "    Parameters\n",
    "    ---------------\n",
    "    only_species : keep only the pictures labelled in picture level\n",
    "    min_images : keep only the taxa that have more than x images\n",
    "    path_to_dataset : dataset to filter in csv\n",
    "            # Path #Labels\n",
    "\n",
    "    Returns \n",
    "    --------------\n",
    "    df_dataset : filtered dataset # Paths # Labels\n",
    "    species : species in filtered dataset # Specie # Nb_img\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    # Take only the images labelled as species (i.e. real labels has more than 1 word)\n",
    "    if only_species:\n",
    "        df_dataset = df_dataset[df_dataset[\"Labels\"].str.contains(\" \")]\n",
    "  \n",
    "    # Get the number of species that have more than min_images images\n",
    "    if min_images is not None : \n",
    "\n",
    "        species = df_dataset['Labels'].value_counts()[df_dataset['Labels'].value_counts() > min_images]\n",
    "\n",
    "        # Convert the series to a dataframe\n",
    "        species = species.to_frame()\n",
    "\n",
    "        # Reset the index\n",
    "        species.reset_index(inplace=True)\n",
    "\n",
    "        # Rename the columns\n",
    "        species.columns = ['Species', 'Number of images']\n",
    "\n",
    "        # Filter the dataset\n",
    "        df_dataset = df_dataset[df_dataset[\"Labels\"].isin(species[\"Species\"])]\n",
    "\n",
    "    return df_dataset, species\n",
    "\n",
    "df_dataset=pd.read_csv(\"/home/basile/Documents/projet_bees_detection_basile/bees_detection/src/datafiles/final_datafiles/dataset_yolo_cropped_with_cleaned_structure.csv\")\n",
    "df_dataset, species = filter_dataset(only_species=True, min_images=100,\n",
    "                                      df_dataset=df_dataset)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2/ Split the filtered dataset into train / test / val "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each specie 80% of the images are used for training 10% for validation and 10% for testing\n",
    "\n",
    "def split_dataset(df_dataset=None, df_dataset__species= None, path_to_output= None):\n",
    "    \"\"\"\n",
    "    Split the dataset into train, valid and test set, \n",
    "    with 80% of the images for training, 10% for validation and 10% for testing\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df_dataset : pandas dataframe of all the pictures\n",
    "                # Paths # Labels\n",
    "    df_dataset_species : pandas dataframe with only the filtered species   \n",
    "                # Species # Number of images\n",
    "    path_to_output : path to the output folder where the csv files will be saved\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    df_train : pandas dataframe of the training set\n",
    "                # Paths # Real labels\n",
    "    df_valid : pandas dataframe of the validation set\n",
    "                # Paths # Real labels\n",
    "    df_test : pandas dataframe of the testing set   \n",
    "                # Paths # Real labels\n",
    "\n",
    "    Csv files :\n",
    "     whole dataset \n",
    "     train/test/val\n",
    "     correspondance label/id\n",
    "    are saved in the output folder\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    # Create empty dataframes\n",
    "    df_train = pd.DataFrame()\n",
    "    df_valid = pd.DataFrame()\n",
    "    df_test = pd.DataFrame()\n",
    "\n",
    "    for specie in species['Species']:\n",
    "\n",
    "        df_img = df_dataset[df_dataset['Labels'] == specie]\n",
    "\n",
    "        # shuffle the dataframe\n",
    "        df_img = df_img.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "        # get the number of images\n",
    "        nb_img = len(df_img)\n",
    "\n",
    "        # get the number of images for each set\n",
    "        nb_img_train = int(nb_img * 0.8)\n",
    "        nb_img_valid = int(nb_img * 0.1)\n",
    "        nb_img_test = int(nb_img * 0.1)\n",
    "\n",
    "        # get the dataframe for each set\n",
    "        df_img_train = df_img.iloc[:nb_img_train]\n",
    "        df_img_valid = df_img.iloc[nb_img_train:nb_img_train+nb_img_valid]\n",
    "        df_img_test = df_img.iloc[nb_img_train+nb_img_valid:]\n",
    "\n",
    "        # Concatenate the dataframe for each set\n",
    "        df_train = pd.concat([df_train, df_img_train])\n",
    "        df_valid = pd.concat([df_valid, df_img_valid])\n",
    "        df_test = pd.concat([df_test, df_img_test])\n",
    "\n",
    "   \n",
    "    # Drop the Real labels column\n",
    "    df_train.drop(columns=['Labels'], inplace=True)\n",
    "    df_valid.drop(columns=['Labels'], inplace=True)\n",
    "    df_test.drop(columns=['Labels'], inplace=True)\n",
    "\n",
    "    if not os.path.exists(path_to_output):\n",
    "        os.mkdir(path_to_output)\n",
    "\n",
    "    # save the dataframe to csv\n",
    "    df_train.to_csv(os.path.join(path_to_output, 'train.csv'), index=False)\n",
    "    df_valid.to_csv(os.path.join(path_to_output, 'valid.csv'), index=False)\n",
    "    df_test.to_csv(os.path.join(path_to_output, 'test.csv'), index=False) \n",
    "\n",
    "    # save the whole dataset to csv\n",
    "    df_dataset.to_csv(os.path.join(path_to_output, 'dataset.csv'), index=False)\n",
    "    species.to_csv(os.path.join(path_to_output,'dataset_summary.csv'),index=False)\n",
    "\n",
    "\n",
    "    return df_train, df_valid, df_test\n",
    "\n",
    "\n",
    "df_train, df_valid, df_test = split_dataset(df_dataset,species,\"/home/basile/Documents/projet_bees_detection_basile/bees_detection/src/datafiles/classification/inputs/VGG16_1\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3/ Create a folder to store this split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_split_to_folder(path_to_folder=None, df_train=None ,df_test=None,df_valid=None,species=None):\n",
    "    \"\"\"\n",
    "    Copy the pictures in a new folder\n",
    "    \"\"\"\n",
    "\n",
    "    # Creates folders\n",
    "    if not os.path.exists(path_to_folder):\n",
    "        os.mkdir(path_to_folder)\n",
    "\n",
    "    names = ['train','test','valid']\n",
    "    dfs = [df_train,df_test,df_valid]\n",
    "\n",
    "    def df_to_folder(df,name):\n",
    "        \n",
    "        if not os.path.exists(os.path.join(path_to_folder,name)):\n",
    "            os.mkdir(os.path.join(path_to_folder,name))\n",
    "\n",
    "        for specie in species['Species']: \n",
    "\n",
    "            if not os.path.exists(os.path.join(path_to_folder,name,specie)):\n",
    "                os.mkdir(os.path.join(path_to_folder,name,specie))\n",
    "\n",
    "      \n",
    "        for old_path in df['Paths']:\n",
    "\n",
    "            new_path = os.path.join(path_to_folder, name,('/').join(old_path.split(os.path.sep)[-2:]))\n",
    "            old_path = os.path.join(old_path)\n",
    "            shutil.copy(old_path,new_path)\n",
    "    \n",
    "\n",
    "    for name,df in zip(names,dfs):\n",
    "        df_to_folder(df,name)\n",
    "\n",
    "\n",
    "copy_split_to_folder(path_to_folder='/home/basile/Documents/projet_bees_detection_basile/data_bees_detection/VGG16_1',df_train=df_train,df_test=df_test,df_valid=df_valid,species=species)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4/ Convert it to dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-03 13:53:06.596808: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-03 13:53:06.749724: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-05-03 13:53:07.556269: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-05-03 13:53:07.556426: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-05-03 13:53:07.556435: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 239652 files belonging to 178 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-03 13:53:13.698083: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-03 13:53:13.712329: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-03 13:53:13.712516: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-03 13:53:13.713750: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-03 13:53:13.714469: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-03 13:53:13.714627: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-03 13:53:13.714751: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-03 13:53:14.195861: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-03 13:53:14.196178: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-03 13:53:14.196261: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-03 13:53:14.196340: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 2631 MB memory:  -> device: 0, name: NVIDIA T600 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 29888 files belonging to 178 classes.\n",
      "Found 30118 files belonging to 178 classes.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras.utils import image_dataset_from_directory\n",
    "\n",
    "IMG_SIZE = 64\n",
    "train_ds = keras.utils.image_dataset_from_directory(\n",
    "    directory= '/home/basile/Documents/projet_bees_detection_basile/data_bees_detection/VGG16_1/train',\n",
    "    labels='inferred',\n",
    "    label_mode='categorical',\n",
    "    shuffle = False,\n",
    "    batch_size=16,\n",
    "    image_size=(IMG_SIZE, IMG_SIZE))\n",
    "\n",
    "valid_ds = keras.utils.image_dataset_from_directory(\n",
    "    directory= '/home/basile/Documents/projet_bees_detection_basile/data_bees_detection/VGG16_1/valid',\n",
    "    labels='inferred',\n",
    "    label_mode='categorical',\n",
    "    shuffle = False,\n",
    "    batch_size=16,\n",
    "    image_size=(IMG_SIZE, IMG_SIZE))\n",
    "\n",
    "test_ds = keras.utils.image_dataset_from_directory(\n",
    "    directory= '/home/basile/Documents/projet_bees_detection_basile/data_bees_detection/VGG16_1/test',\n",
    "    labels='inferred',\n",
    "    label_mode='categorical',\n",
    "    shuffle = False,\n",
    "    batch_size=16,\n",
    "    image_size=(IMG_SIZE, IMG_SIZE))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset element_spec=(TensorSpec(shape=(None, 64, 64, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None, 178), dtype=tf.float32, name=None))>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 64, 64, 3)\n",
      "(16, 178)\n"
     ]
    }
   ],
   "source": [
    "for element in train_ds:\n",
    "    for ele in element:\n",
    "        print(ele.shape)\n",
    "    break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5/ Convert to x /y \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_to_numpy(dataset):\n",
    "    \"\"\"\n",
    "    Transform a dataset to a numpy array\n",
    "    \"\"\"\n",
    "    x = np.array(dataset.file_paths)\n",
    "    NB_FILES = len(x)\n",
    "    NB_CLASSES = len(dataset.class_names)\n",
    "    y = np.zeros((NB_FILES,NB_CLASSES))\n",
    "\n",
    "    ind_data = 0\n",
    "    for bx, by in dataset.as_numpy_iterator():\n",
    "        y[ind_data:ind_data+bx.shape[0]] = by\n",
    "        ind_data += bx.shape[0]\n",
    "\n",
    "    return x,y"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CREATE MODEL"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1/ Compile model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.vgg16 import VGG16\n",
    "\n",
    "model = VGG16(input_shape=(IMG_SIZE, IMG_SIZE, 3),include_top=False)\n",
    "\n",
    "# NB_CLASSES = species.shape[0]\n",
    "NB_CLASSES = 178\n",
    "\n",
    "\n",
    "# create a classifier model on top\n",
    "x = model.output\n",
    "x = keras.layers.Flatten()(x)\n",
    "x = keras.layers.Dense(1024, activation='relu')(x)\n",
    "predictions = keras.layers.Dense(NB_CLASSES, activation='softmax')(x)\n",
    "\n",
    "# combine the two models\n",
    "model = keras.Model(inputs=model.input, outputs=predictions)\n",
    "\n",
    "# set parameters for training\n",
    "EPOCHS = 1\n",
    "BATCH_SIZE = 5\n",
    "OPTI = keras.optimizers.Adam(learning_rate=0.001, decay=1e-6)\n",
    "LOSS = keras.losses.CategoricalCrossentropy()\n",
    "METRICS = [ keras.metrics.Precision(name='precision'), keras.metrics.Recall(name='recall')]\n",
    "\n",
    "# compile model\n",
    "model.compile(optimizer=OPTI, loss=LOSS, metrics=METRICS)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_4 (InputLayer)        [(None, 64, 64, 3)]       0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 64, 64, 64)        1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 64, 64, 64)        36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 32, 32, 64)        0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 32, 32, 128)       73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 32, 32, 128)       147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 16, 16, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 16, 16, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 16, 16, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 16, 16, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 8, 8, 256)         0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 8, 8, 512)         1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 8, 8, 512)         2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 8, 8, 512)         2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 4, 4, 512)         0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 4, 4, 512)         2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 4, 4, 512)         2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 4, 4, 512)         2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 2, 2, 512)         0         \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 2048)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1024)              2098176   \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 178)               182450    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 16,995,314\n",
      "Trainable params: 16,995,314\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2/ Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# callbacks\n",
    "model_checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath='/home/basile/Documents/projet_bees_detection_basile/bees_detection/src/datafiles/classification/saved_weights/VGG16_1.h5',\n",
    "    save_weights_only=True,\n",
    "    monitor='val_loss',\n",
    "    mode='min',\n",
    "    save_best_only=True,\n",
    "    #save_freq=16,\n",
    "    verbose=1)\n",
    "\n",
    "early_stopping_cb = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    min_delta=0.01,\n",
    "    patience=10,\n",
    "    verbose=1,\n",
    "    mode=\"auto\")\n",
    "\n",
    "reduce_lr_cb = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1,\n",
    "                              patience=5, min_lr=0.00001, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history =model.fit(train_ds,validation_data=valid_ds,epochs=EPOCHS, batch_size=BATCH_SIZE,callbacks=[model_checkpoint_cb,early_stopping_cb,reduce_lr_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m history\u001b[39m.\u001b[39mhistory\u001b[39m.\u001b[39mkeys()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    }
   ],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# evaluate model\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \n\u001b[1;32m      3\u001b[0m \u001b[39m# load best weights\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m model\u001b[39m.\u001b[39mload_weights(\u001b[39m'\u001b[39m\u001b[39m/home/basile/Documents/projet_bees_detection_basile/bees_detection/src/datafiles/classification/saved_weights/VGG16_1.h5\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      6\u001b[0m \u001b[39m# evaluate model\u001b[39;00m\n\u001b[1;32m      7\u001b[0m model\u001b[39m.\u001b[39mevaluate(test_ds)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "# evaluate model\n",
    "\n",
    "# load best weights\n",
    "model.load_weights('/home/basile/Documents/projet_bees_detection_basile/bees_detection/src/datafiles/classification/saved_weights/VGG16_1.h5')\n",
    "\n",
    "# evaluate model\n",
    "model.evaluate(test_ds)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "def plot_training_analysis(history, metric='loss'):    \n",
    "\n",
    "  loss = history.history[metric]\n",
    "  val_loss = history.history['val_' + metric]\n",
    "\n",
    "  epochs = range(len(loss))\n",
    "\n",
    "  plt.plot(epochs, loss, 'b', linestyle=\"--\",label='Training ' + metric)\n",
    "  plt.plot(epochs, val_loss, 'g', label='Validation ' + metric)\n",
    "  plt.title('Training and validation ' + metric)\n",
    "  plt.legend()\n",
    "\n",
    "  plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
