{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Generate train test val \n",
    "\n",
    "To start with, we'll create a simple dataset for our VGG16 \n",
    "- only images labelled at species level\n",
    "- only species with more than pictures \n",
    "- no hierarchy between databases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import pandas as pd \n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Paths</th>\n",
       "      <th>Real labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/home/basile/Documents/projet_bees_detection_b...</td>\n",
       "      <td>Hylaeus pictus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/home/basile/Documents/projet_bees_detection_b...</td>\n",
       "      <td>Hylaeus pictus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/home/basile/Documents/projet_bees_detection_b...</td>\n",
       "      <td>Hylaeus pictus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/home/basile/Documents/projet_bees_detection_b...</td>\n",
       "      <td>Hylaeus pictus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/home/basile/Documents/projet_bees_detection_b...</td>\n",
       "      <td>Hylaeus pictus</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Paths     Real labels\n",
       "0  /home/basile/Documents/projet_bees_detection_b...  Hylaeus pictus\n",
       "1  /home/basile/Documents/projet_bees_detection_b...  Hylaeus pictus\n",
       "2  /home/basile/Documents/projet_bees_detection_b...  Hylaeus pictus\n",
       "3  /home/basile/Documents/projet_bees_detection_b...  Hylaeus pictus\n",
       "4  /home/basile/Documents/projet_bees_detection_b...  Hylaeus pictus"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_to_dataset = '/home/basile/Documents/projet_bees_detection_basile/bees_detection/src/datafiles/final_datafiles/dataset_yolo_cropped_with_real_labels.csv'\n",
    "\n",
    "df_dataset = pd.read_csv(path_to_dataset)\n",
    "df_dataset.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select species that fit the conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take only the images labelled as species (i.e. real labels has more than 1 word)\n",
    "df_dataset_species = df_dataset[df_dataset['Real labels'].str.split(' ').str.len() > 1]\n",
    "\n",
    "\n",
    "# Get the number of species that have more than 100 images\n",
    "df_dataset_species = df_dataset_species['Real labels'].value_counts()[df_dataset_species['Real labels'].value_counts() > 20000]\n",
    "\n",
    "# Convert the series to a dataframe\n",
    "df_dataset_species = df_dataset_species.to_frame()\n",
    "\n",
    "# Reset the index\n",
    "df_dataset_species.reset_index(inplace=True)\n",
    "\n",
    "# Rename the columns\n",
    "df_dataset_species.columns = ['Species', 'Number of images']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Species</th>\n",
       "      <th>Number of images</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Apis mellifera</td>\n",
       "      <td>49093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bombus terrestris</td>\n",
       "      <td>20535</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Species  Number of images\n",
       "0     Apis mellifera             49093\n",
       "1  Bombus terrestris             20535"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dataset_species.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creates an index for each specie, so that we can generate datasets with paths_and_labels_to_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def associate_label_to_index(df_dataset): \n",
    "    \"\"\"\n",
    "    Associate an integer to each label\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df_dataset : pandas dataframe of all the pictures\n",
    "                # Paths # Real labels\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    df_dataset : pandas dataframe of all the pictures\n",
    "                # Paths # Real labels # Id\n",
    "    \"\"\"\n",
    "\n",
    "    # Get the unique labels\n",
    "    labels = df_dataset['Real labels'].unique()\n",
    "\n",
    "    # Create a dictionary with the labels as keys and the integers as values\n",
    "    label_to_index = dict((label, index) for index, label in enumerate(labels))\n",
    "\n",
    "    # Add a column with the integer label\n",
    "    df_dataset['Id'] = df_dataset['Real labels'].map(label_to_index)\n",
    "\n",
    "    return df_dataset\n",
    "\n",
    "df_dataset = associate_label_to_index(df_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Paths</th>\n",
       "      <th>Real labels</th>\n",
       "      <th>Id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/home/basile/Documents/projet_bees_detection_b...</td>\n",
       "      <td>Andrena wilkella</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/home/basile/Documents/projet_bees_detection_b...</td>\n",
       "      <td>Apis mellifera</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/home/basile/Documents/projet_bees_detection_b...</td>\n",
       "      <td>Apis mellifera</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/home/basile/Documents/projet_bees_detection_b...</td>\n",
       "      <td>Bombus pascuorum</td>\n",
       "      <td>240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/home/basile/Documents/projet_bees_detection_b...</td>\n",
       "      <td>Andrena fulva</td>\n",
       "      <td>187</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Paths       Real labels   Id\n",
       "0  /home/basile/Documents/projet_bees_detection_b...  Andrena wilkella   45\n",
       "1  /home/basile/Documents/projet_bees_detection_b...    Apis mellifera   97\n",
       "2  /home/basile/Documents/projet_bees_detection_b...    Apis mellifera   97\n",
       "3  /home/basile/Documents/projet_bees_detection_b...  Bombus pascuorum  240\n",
       "4  /home/basile/Documents/projet_bees_detection_b...     Andrena fulva  187"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sguffle the dataset\n",
    "df_dataset = df_dataset.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "df_dataset.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the pictures between train / test / val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each specie 80% of the images are used for training 10% for validation and 10% for testing\n",
    "\n",
    "def split_dataset(\n",
    "        df_dataset, df_dataset__species,\n",
    "        path_to_output= '/home/basile/Documents/projet_bees_detection_basile/bees_detection/src/datafiles/classification/inputs/VGG16_little'\n",
    "):\n",
    "    \"\"\"\n",
    "    Split the dataset into train, valid and test set, \n",
    "    with 80% of the images for training, 10% for validation and 10% for testing\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df_dataset : pandas dataframe of all the pictures\n",
    "                # Paths # Real labels # Id\n",
    "    df_dataset_species : pandas dataframe with only the filtered species   \n",
    "                # Species # Number of images\n",
    "    path_to_output : path to the output folder where the csv files will be saved\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    df_train : pandas dataframe of the training set\n",
    "                # Paths # Real labels\n",
    "    df_valid : pandas dataframe of the validation set\n",
    "                # Paths # Real labels\n",
    "    df_test : pandas dataframe of the testing set   \n",
    "                # Paths # Real labels\n",
    "\n",
    "    Csv files :\n",
    "     whole dataset \n",
    "     train/test/val\n",
    "     correspondance label/id\n",
    "    are saved in the output folder\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "\n",
    "    # Create empty dataframes\n",
    "    df_train = pd.DataFrame()\n",
    "    df_valid = pd.DataFrame()\n",
    "    df_test = pd.DataFrame()\n",
    "\n",
    "    for specie in df_dataset_species['Species']:\n",
    "\n",
    "        df_img = df_dataset[df_dataset['Real labels'] == specie]\n",
    "\n",
    "        # shuffle the dataframe\n",
    "        df_img = df_img.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "        # get the number of images\n",
    "        nb_img = len(df_img)\n",
    "\n",
    "        # get the number of images for each set\n",
    "        nb_img_train = int(nb_img * 0.8)\n",
    "        nb_img_valid = int(nb_img * 0.1)\n",
    "        nb_img_test = int(nb_img * 0.1)\n",
    "\n",
    "        # get the dataframe for each set\n",
    "        df_img_train = df_img.iloc[:nb_img_train]\n",
    "        df_img_valid = df_img.iloc[nb_img_train:nb_img_train+nb_img_valid]\n",
    "        df_img_test = df_img.iloc[nb_img_train+nb_img_valid:]\n",
    "\n",
    "        # Concatenate the dataframe for each set\n",
    "        df_train = pd.concat([df_train, df_img_train])\n",
    "        df_valid = pd.concat([df_valid, df_img_valid])\n",
    "        df_test = pd.concat([df_test, df_img_test])\n",
    "\n",
    "    # shuffle the dataframe\n",
    "    df_train = df_train.sample(frac=1).reset_index(drop=True)\n",
    "    df_valid = df_valid.sample(frac=1).reset_index(drop=True)\n",
    "    df_test = df_test.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "    # Drop the Real labels column\n",
    "    df_train.drop(columns=['Real labels'], inplace=True)\n",
    "    df_valid.drop(columns=['Real labels'], inplace=True)\n",
    "    df_test.drop(columns=['Real labels'], inplace=True)\n",
    "\n",
    "\n",
    "    # save the dataframe to csv\n",
    "    df_train.to_csv(os.path.join(path_to_output, 'train.csv'), index=False)\n",
    "    df_valid.to_csv(os.path.join(path_to_output, 'valid.csv'), index=False)\n",
    "    df_test.to_csv(os.path.join(path_to_output, 'test.csv'), index=False) \n",
    "\n",
    "    # save the whole dataset to csv\n",
    "    df_dataset.to_csv(os.path.join(path_to_output, 'dataset.csv'), index=False)\n",
    "\n",
    "    # save the correspondance label/id to csv\n",
    "    df_dataset[['Id', 'Real labels']].drop_duplicates().to_csv(os.path.join(path_to_output, 'label_id.csv'), index=False)\n",
    "    \n",
    "\n",
    "    return df_train, df_valid, df_test\n",
    "\n",
    "\n",
    "df_train, df_valid, df_test = split_dataset(df_dataset, df_dataset_species)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def copy_pictures_from_csv(df, path_to_output):\n",
    "#     \"\"\"\n",
    "#     param df: dataframe with the paths to the images \n",
    "#             like this # paths #labels\n",
    "#             NB : paths is : whole_dataset_cropped/.../image.jpg\n",
    "#     param path_to_output: path to the folder where the images will be copied \n",
    "#             e.g. VGG16/train\n",
    "#     \"\"\"\n",
    "#     # copy pictures\n",
    "#     for index, row in df.iterrows():\n",
    "#         path_to_file = row['Paths']\n",
    "#         path_to_file = path_to_file.replace('whole_dataset_cropped', path_to_output)\n",
    "#         os.makedirs(os.path.dirname(path_to_file), exist_ok=True)\n",
    "#         os.system('cp \"{}\" \"{}\"'.format(row['Paths'], path_to_file))\n",
    "\n",
    "#     # write new csv\n",
    "\n",
    "#     df['Paths'] = df['Paths'].str.replace('whole_dataset_cropped', path_to_output)\n",
    "#     df.to_csv(os.path.join(path_to_output, 'dataset.csv'), index=False)\n",
    "\n",
    "\n",
    "# copy_pictures_from_csv(df_train, 'VGG16/train')\n",
    "# copy_pictures_from_csv(df_valid, 'VGG16/valid')\n",
    "# copy_pictures_from_csv(df_test, 'VGG16/test')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Create datasets\n",
    "\n",
    "Using paths_and_labels_to_dataset so as to save memory and keep the actual folder structure\n",
    "\n",
    "(we've modified the code to import and use it) :\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from keras.utils import paths_and_labels_to_dataset\n",
    "\n",
    "def dataframe_to_dataset(df,batch_size):\n",
    "    \"\"\"\n",
    "    Converts a dataframe to a tensorflow dataset\n",
    "    Parameters\n",
    "    ----------\n",
    "    df: dataframe with the paths to the images \n",
    "            like this # paths #labels\n",
    "    batch size : batch size for the dataset\n",
    "    Returns\n",
    "    -------\n",
    "    dataset : tensorflow dataset\n",
    "    \"\"\"\n",
    "\n",
    "    ds = paths_and_labels_to_dataset(\n",
    "        image_paths = df['Paths'].values,\n",
    "        image_size = (64,64),\n",
    "        num_channels= 3,\n",
    "        labels = df['Id'].values,\n",
    "        label_mode = 'categorical',\n",
    "        num_classes = df['Id'].nunique(),\n",
    "        interpolation = 'bilinear',\n",
    "        crop_to_aspect_ratio=False)\n",
    "    \n",
    "    ds = ds.batch(batch_size)\n",
    "\n",
    "    return ds\n",
    "\n",
    "train_ds = dataframe_to_dataset(df_train, 1)\n",
    "valid_ds = dataframe_to_dataset(df_valid, 1)\n",
    "test_ds = dataframe_to_dataset(df_test, 1)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# train_ds = paths_and_labels_to_dataset(\n",
    "#     image_paths = df_train['Paths'].values,\n",
    "#     image_size = (64,64),\n",
    "#     num_channels= 3,\n",
    "#     labels = df_train['Id'].values,\n",
    "#     label_mode = 'categorical',\n",
    "#     num_classes = df_train['Id'].nunique(),\n",
    "#     interpolation = 'bilinear',\n",
    "#     crop_to_aspect_ratio=False)\n",
    "\n",
    "\n",
    "\n",
    "# test_ds = paths_and_labels_to_dataset(\n",
    "#     image_paths = df_test['Paths'].values,\n",
    "#     image_size = (64,64),\n",
    "#     num_channels= 3,\n",
    "#     labels = df_test['Id'].values,\n",
    "#     label_mode = 'categorical',\n",
    "#     num_classes = df_test['Id'].nunique(),\n",
    "#     interpolation = 'bilinear',\n",
    "#     crop_to_aspect_ratio=False)\n",
    "\n",
    "# valid_ds = paths_and_labels_to_dataset(\n",
    "#     image_paths = df_valid['Paths'].values,\n",
    "#     image_size = (64,64),\n",
    "#     num_channels= 3,\n",
    "#     labels = df_valid['Id'].values,\n",
    "#     label_mode = 'categorical',\n",
    "#     num_classes = df_valid['Id'].nunique(),\n",
    "#     interpolation = 'bilinear',\n",
    "#     crop_to_aspect_ratio=False)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_4 (InputLayer)        [(None, 64, 64, 3)]       0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 64, 64, 64)        1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 64, 64, 64)        36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 32, 32, 64)        0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 32, 32, 128)       73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 32, 32, 128)       147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 16, 16, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 16, 16, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 16, 16, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 16, 16, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 8, 8, 256)         0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 8, 8, 512)         1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 8, 8, 512)         2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 8, 8, 512)         2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 4, 4, 512)         0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 4, 4, 512)         2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 4, 4, 512)         2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 4, 4, 512)         2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 2, 2, 512)         0         \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 2048)              0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 1024)              2098176   \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 2)                 2050      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 16,814,914\n",
      "Trainable params: 16,814,914\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras.applications import VGG16\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Flatten\n",
    "\n",
    "# load model without classifier layers\n",
    "model = VGG16(include_top=False, input_shape=(64, 64, 3))\n",
    "\n",
    "# Number of classes in the dataset\n",
    "num_classes = df_train['Id'].nunique()\n",
    "\n",
    "# add new classifier layers\n",
    "flat1 = Flatten()(model.layers[-1].output)\n",
    "class1 = Dense(1024, activation='relu')(flat1)\n",
    "output = Dense(num_classes, activation='softmax')(class1)\n",
    "\n",
    "# define new model\n",
    "model = Model(inputs=model.inputs, outputs=output)\n",
    "\n",
    "# summarize\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the optimizer, loss function and metrics\n",
    "\n",
    "opti = tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
    "loss = tf.keras.losses.CategoricalCrossentropy()\n",
    "metrics = [tf.keras.metrics.Precision(), tf.keras.metrics.Recall()]\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=opti, loss=loss, metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 2267/55702 [>.............................] - ETA: 24:50 - loss: nan - precision_2: 0.0000e+00 - recall_2: 0.0000e+00"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-02 16:08:55.692649: W tensorflow/core/lib/png/png_io.cc:88] PNG warning: iCCP: extra compressed data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 3597/55702 [>.............................] - ETA: 24:11 - loss: nan - precision_2: 0.0000e+00 - recall_2: 0.0000e+00"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-02 16:09:32.701013: W tensorflow/core/lib/png/png_io.cc:88] PNG warning: iCCP: extra compressed data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 3851/55702 [=>............................] - ETA: 24:04 - loss: nan - precision_2: 0.0000e+00 - recall_2: 0.0000e+00"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-02 16:09:39.763509: W tensorflow/core/lib/png/png_io.cc:88] PNG warning: iCCP: extra compressed data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 8537/55702 [===>..........................] - ETA: 21:55 - loss: nan - precision_2: 0.0000e+00 - recall_2: 0.0000e+00"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-02 16:11:50.656011: W tensorflow/core/lib/png/png_io.cc:88] PNG warning: iCCP: extra compressed data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13435/55702 [======>.......................] - ETA: 20:35 - loss: nan - precision_2: 0.0000e+00 - recall_2: 0.0000e+00"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[68], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Fit the model\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(train_ds, validation_data\u001b[39m=\u001b[39;49mvalid_ds, epochs\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[1;32m      4\u001b[0m \u001b[39m# Evaluate the model\u001b[39;00m\n\u001b[1;32m      5\u001b[0m model\u001b[39m.\u001b[39mevaluate(test_ds)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/utils/traceback_utils.py:61\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39merror_handler\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     60\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m tf\u001b[39m.\u001b[39mdebugging\u001b[39m.\u001b[39mis_traceback_filtering_enabled():\n\u001b[0;32m---> 61\u001b[0m         \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     63\u001b[0m     filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m     \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/engine/training.py:1656\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1654\u001b[0m logs \u001b[39m=\u001b[39m tmp_logs\n\u001b[1;32m   1655\u001b[0m end_step \u001b[39m=\u001b[39m step \u001b[39m+\u001b[39m data_handler\u001b[39m.\u001b[39mstep_increment\n\u001b[0;32m-> 1656\u001b[0m callbacks\u001b[39m.\u001b[39;49mon_train_batch_end(end_step, logs)\n\u001b[1;32m   1657\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstop_training:\n\u001b[1;32m   1658\u001b[0m     \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/callbacks.py:476\u001b[0m, in \u001b[0;36mCallbackList.on_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    469\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Calls the `on_train_batch_end` methods of its callbacks.\u001b[39;00m\n\u001b[1;32m    470\u001b[0m \n\u001b[1;32m    471\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[1;32m    472\u001b[0m \u001b[39m    batch: Integer, index of batch within the current epoch.\u001b[39;00m\n\u001b[1;32m    473\u001b[0m \u001b[39m    logs: Dict. Aggregated metric results up until this batch.\u001b[39;00m\n\u001b[1;32m    474\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    475\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_should_call_train_batch_hooks:\n\u001b[0;32m--> 476\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_batch_hook(ModeKeys\u001b[39m.\u001b[39;49mTRAIN, \u001b[39m\"\u001b[39;49m\u001b[39mend\u001b[39;49m\u001b[39m\"\u001b[39;49m, batch, logs\u001b[39m=\u001b[39;49mlogs)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/callbacks.py:323\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    321\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_batch_begin_hook(mode, batch, logs)\n\u001b[1;32m    322\u001b[0m \u001b[39melif\u001b[39;00m hook \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mend\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m--> 323\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_batch_end_hook(mode, batch, logs)\n\u001b[1;32m    324\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    325\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    326\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mUnrecognized hook: \u001b[39m\u001b[39m{\u001b[39;00mhook\u001b[39m}\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    327\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mExpected values are [\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbegin\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m\u001b[39mend\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m]\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    328\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/callbacks.py:346\u001b[0m, in \u001b[0;36mCallbackList._call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    343\u001b[0m     batch_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_batch_start_time\n\u001b[1;32m    344\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_batch_times\u001b[39m.\u001b[39mappend(batch_time)\n\u001b[0;32m--> 346\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_batch_hook_helper(hook_name, batch, logs)\n\u001b[1;32m    348\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_batch_times) \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_batches_for_timing_check:\n\u001b[1;32m    349\u001b[0m     end_hook_name \u001b[39m=\u001b[39m hook_name\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/callbacks.py:394\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    392\u001b[0m \u001b[39mfor\u001b[39;00m callback \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallbacks:\n\u001b[1;32m    393\u001b[0m     hook \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(callback, hook_name)\n\u001b[0;32m--> 394\u001b[0m     hook(batch, logs)\n\u001b[1;32m    396\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_timing:\n\u001b[1;32m    397\u001b[0m     \u001b[39mif\u001b[39;00m hook_name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_hook_times:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/callbacks.py:1094\u001b[0m, in \u001b[0;36mProgbarLogger.on_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1093\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mon_train_batch_end\u001b[39m(\u001b[39mself\u001b[39m, batch, logs\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m-> 1094\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_batch_update_progbar(batch, logs)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/callbacks.py:1170\u001b[0m, in \u001b[0;36mProgbarLogger._batch_update_progbar\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1166\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mseen \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m add_seen\n\u001b[1;32m   1168\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   1169\u001b[0m     \u001b[39m# Only block async when verbose = 1.\u001b[39;00m\n\u001b[0;32m-> 1170\u001b[0m     logs \u001b[39m=\u001b[39m tf_utils\u001b[39m.\u001b[39;49msync_to_numpy_or_python_type(logs)\n\u001b[1;32m   1171\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprogbar\u001b[39m.\u001b[39mupdate(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mseen, \u001b[39mlist\u001b[39m(logs\u001b[39m.\u001b[39mitems()), finalize\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/utils/tf_utils.py:665\u001b[0m, in \u001b[0;36msync_to_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    662\u001b[0m         \u001b[39mreturn\u001b[39;00m t\n\u001b[1;32m    663\u001b[0m     \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mitem() \u001b[39mif\u001b[39;00m np\u001b[39m.\u001b[39mndim(t) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m \u001b[39melse\u001b[39;00m t\n\u001b[0;32m--> 665\u001b[0m \u001b[39mreturn\u001b[39;00m tf\u001b[39m.\u001b[39;49mnest\u001b[39m.\u001b[39;49mmap_structure(_to_single_numpy_or_python_type, tensors)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/util/nest.py:917\u001b[0m, in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    913\u001b[0m flat_structure \u001b[39m=\u001b[39m (flatten(s, expand_composites) \u001b[39mfor\u001b[39;00m s \u001b[39min\u001b[39;00m structure)\n\u001b[1;32m    914\u001b[0m entries \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mflat_structure)\n\u001b[1;32m    916\u001b[0m \u001b[39mreturn\u001b[39;00m pack_sequence_as(\n\u001b[0;32m--> 917\u001b[0m     structure[\u001b[39m0\u001b[39m], [func(\u001b[39m*\u001b[39mx) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m entries],\n\u001b[1;32m    918\u001b[0m     expand_composites\u001b[39m=\u001b[39mexpand_composites)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/util/nest.py:917\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    913\u001b[0m flat_structure \u001b[39m=\u001b[39m (flatten(s, expand_composites) \u001b[39mfor\u001b[39;00m s \u001b[39min\u001b[39;00m structure)\n\u001b[1;32m    914\u001b[0m entries \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mflat_structure)\n\u001b[1;32m    916\u001b[0m \u001b[39mreturn\u001b[39;00m pack_sequence_as(\n\u001b[0;32m--> 917\u001b[0m     structure[\u001b[39m0\u001b[39m], [func(\u001b[39m*\u001b[39;49mx) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m entries],\n\u001b[1;32m    918\u001b[0m     expand_composites\u001b[39m=\u001b[39mexpand_composites)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/utils/tf_utils.py:658\u001b[0m, in \u001b[0;36msync_to_numpy_or_python_type.<locals>._to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    655\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_to_single_numpy_or_python_type\u001b[39m(t):\n\u001b[1;32m    656\u001b[0m     \u001b[39m# Don't turn ragged or sparse tensors to NumPy.\u001b[39;00m\n\u001b[1;32m    657\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(t, tf\u001b[39m.\u001b[39mTensor):\n\u001b[0;32m--> 658\u001b[0m         t \u001b[39m=\u001b[39m t\u001b[39m.\u001b[39;49mnumpy()\n\u001b[1;32m    659\u001b[0m     \u001b[39m# Strings, ragged and sparse tensors don't have .item(). Return them\u001b[39;00m\n\u001b[1;32m    660\u001b[0m     \u001b[39m# as-is.\u001b[39;00m\n\u001b[1;32m    661\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(t, (np\u001b[39m.\u001b[39mndarray, np\u001b[39m.\u001b[39mgeneric)):\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/framework/ops.py:1155\u001b[0m, in \u001b[0;36m_EagerTensorBase.numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1132\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Copy of the contents of this Tensor into a NumPy array or scalar.\u001b[39;00m\n\u001b[1;32m   1133\u001b[0m \n\u001b[1;32m   1134\u001b[0m \u001b[39mUnlike NumPy arrays, Tensors are immutable, so this method has to copy\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1152\u001b[0m \u001b[39m    NumPy dtype.\u001b[39;00m\n\u001b[1;32m   1153\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1154\u001b[0m \u001b[39m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[39;00m\n\u001b[0;32m-> 1155\u001b[0m maybe_arr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_numpy()  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m   1156\u001b[0m \u001b[39mreturn\u001b[39;00m maybe_arr\u001b[39m.\u001b[39mcopy() \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(maybe_arr, np\u001b[39m.\u001b[39mndarray) \u001b[39melse\u001b[39;00m maybe_arr\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/framework/ops.py:1121\u001b[0m, in \u001b[0;36m_EagerTensorBase._numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1119\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_numpy\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m   1120\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1121\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_numpy_internal()\n\u001b[1;32m   1122\u001b[0m   \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m   1123\u001b[0m     \u001b[39mraise\u001b[39;00m core\u001b[39m.\u001b[39m_status_to_exception(e) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "history = model.fit(train_ds, validation_data=valid_ds, epochs=1)\n",
    "\n",
    "# Evaluate the model\n",
    "model.evaluate(test_ds)\n",
    "\n",
    "# Plot the training and validation loss\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='valid')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_bees",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
