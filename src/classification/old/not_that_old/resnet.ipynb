{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-23 14:01:14.917385: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-23 14:01:15.053410: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-05-23 14:01:15.677211: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-05-23 14:01:15.677263: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-05-23 14:01:15.677267: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils import image_dataset_from_directory"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CREATE DATASETS AND PROPER FOLDER STUCTURE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_datasets_and_directories(path_to_csv,path_to_output,cap,nb_img_to_keep,only_species=True,image_size=128):\n",
    "\n",
    "    \"\"\"\n",
    "    Given a dataset of cropped images, create the train, validation and test folders.\n",
    "    Only keeps the images with more than cap images in the dataset, keeps only nb_img_to_keep images per class.\n",
    "    Split for train, validation and test is 80/10/10.\n",
    "    \n",
    "    args : \n",
    "\n",
    "    path_to_csv : path to the csv file containing the dataset\n",
    "                    # paths , # labels \n",
    "    path_to_output : path to the output folder were folders will be created\n",
    "                     in this format : \n",
    "                        output_folder\n",
    "                            - train\n",
    "                            - validation\n",
    "                            - test\n",
    "                            - train_dataset.csv\n",
    "                            - validation_dataset.csv\n",
    "                            - test_dataset.csv\n",
    "                            - weights.h5\n",
    "    cap : minimum number of images per class, if None no cap\n",
    "    nb_img_to_keep : number of images to keep per class, if None keep all images\n",
    "    only_species : if True, only keeps the images labelled as species (i.e. real labels has more than 1 word) \n",
    "                     if False, keeps all the images\n",
    "    image_size : size of the images to resize to\n",
    "    TODO : integrate the only_species = False\n",
    "    \n",
    "    Returns : \n",
    "        train_dataset, validation_dataset, test_dataset : Dataset objects\n",
    "    \"\"\"\n",
    "\n",
    "    ###### FILTER THE DATASET ######\n",
    "\n",
    "    # read the csv file\n",
    "    df_dataset = pd.read_csv(path_to_csv)\n",
    "    \n",
    "    # Take only the images labelled as species (i.e. real labels has more than 1 word)\n",
    "    if only_species:\n",
    "        df_dataset = df_dataset[df_dataset[\"Labels\"].str.contains(\" \")]\n",
    "  \n",
    "    # Get the number of species that have more than cap images\n",
    "    if cap is not None : \n",
    "        species = df_dataset['Labels'].value_counts()[df_dataset['Labels'].value_counts() > cap]\n",
    "\n",
    "        # Convert the series to a dataframe\n",
    "        species = species.to_frame()\n",
    "\n",
    "        # Reset the index\n",
    "        species.reset_index(inplace=True)\n",
    "\n",
    "        # Rename the columns\n",
    "        species.columns = ['Species', 'Number of images']\n",
    "\n",
    "        # Filter the dataset\n",
    "        df_dataset = df_dataset[df_dataset[\"Labels\"].isin(species[\"Species\"])]\n",
    "\n",
    "        print(\"Number of species with more than {} images : {}\".format(cap, len(species)))\n",
    "        print(\"Number of images in the filtered dataset : {}\".format(len(df_dataset)))\n",
    "\n",
    "        print('-'*50)\n",
    "\n",
    "        print(df_dataset['Labels'].value_counts())\n",
    "\n",
    "    if nb_img_to_keep is not None : \n",
    "        \n",
    "        dataset = df_dataset.groupby('Labels').head(nb_img_to_keep)\n",
    "\n",
    "    #### SPLITS THE DATASET #####\n",
    "\n",
    "    train_dataset = dataset.sample(frac=0.8, random_state=0)\n",
    "    test_dataset = dataset.drop(train_dataset.index)\n",
    "\n",
    "    train_dataset = train_dataset.reset_index(drop=True)\n",
    "    test_dataset = test_dataset.reset_index(drop=True)\n",
    "\n",
    "    train_dataset, val_dataset = train_test_split(train_dataset, test_size=0.2, random_state=0)\n",
    "\n",
    "    ###### CREATE THE FOLDER STRUCTURE ######\n",
    "\n",
    "    if os.path.exists(path_to_output):\n",
    "        shutil.rmtree(path_to_output)\n",
    "\n",
    "    os.makedirs(path_to_output)\n",
    "\n",
    "    os.makedirs(path_to_output + \"/train\")\n",
    "    os.makedirs(path_to_output + \"/validation\")\n",
    "    os.makedirs(path_to_output + \"/test\")\n",
    "\n",
    "    ###### COPY THE IMAGES TO THE FOLDERS ######\n",
    "\n",
    "    for index, row in train_dataset.iterrows():\n",
    "\n",
    "        # Create the folder if it does not exist\n",
    "        if not os.path.exists(path_to_output + \"/train/\" + row[\"Labels\"]):\n",
    "            os.makedirs(path_to_output + \"/train/\" + row[\"Labels\"])\n",
    "\n",
    "        # Copy the image\n",
    "        shutil.copy(row[\"Paths\"], path_to_output + \"/train/\" + row[\"Labels\"])\n",
    "\n",
    "    for index, row in val_dataset.iterrows():\n",
    "            \n",
    "            # Create the folder if it does not exist\n",
    "            if not os.path.exists(path_to_output + \"/validation/\" + row[\"Labels\"]):\n",
    "                os.makedirs(path_to_output + \"/validation/\" + row[\"Labels\"])\n",
    "    \n",
    "            # Copy the image\n",
    "            shutil.copy(row[\"Paths\"], path_to_output + \"/validation/\" + row[\"Labels\"])\n",
    "\n",
    "    for index, row in test_dataset.iterrows():\n",
    "\n",
    "        # Create the folder if it does not exist\n",
    "        if not os.path.exists(path_to_output + \"/test/\" + row[\"Labels\"]):\n",
    "            os.makedirs(path_to_output + \"/test/\" + row[\"Labels\"])\n",
    "\n",
    "        # Copy the image\n",
    "        shutil.copy(row[\"Paths\"], path_to_output + \"/test/\" + row[\"Labels\"])\n",
    "\n",
    "    ###### CREATE THE CSV FILES ######\n",
    "\n",
    "    train_dataset.to_csv(path_to_output + \"/train_dataset.csv\", index=False)\n",
    "    val_dataset.to_csv(path_to_output + \"/validation_dataset.csv\", index=False)\n",
    "    test_dataset.to_csv(path_to_output + \"/test_dataset.csv\", index=False)\n",
    "\n",
    "\n",
    "    ##### MAKE THE DATASET OBJECTS #####\n",
    "\n",
    "    train_dataset = image_dataset_from_directory(os.path.join(path_to_output,\"train\"), shuffle=True, batch_size=32, image_size=(image_size,image_size),labels = 'inferred',label_mode= 'categorical')\n",
    "    test_dataset = image_dataset_from_directory(os.path.join(path_to_output,\"test\"), shuffle=True, batch_size=32, image_size=(image_size,image_size),labels = 'inferred',label_mode= 'categorical')\n",
    "    val_dataset = image_dataset_from_directory(os.path.join(path_to_output,\"validation\" ),shuffle=True, batch_size=32, image_size=(image_size,image_size),labels = 'inferred',label_mode= 'categorical')\n",
    "\n",
    "    return train_dataset, val_dataset, test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of species with more than 20000 images : 2\n",
      "Number of images in the filtered dataset : 69628\n",
      "--------------------------------------------------\n",
      "Apis mellifera       49093\n",
      "Bombus terrestris    20535\n",
      "Name: Labels, dtype: int64\n",
      "Found 25 files belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-23 14:01:17.772316: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-23 14:01:17.786925: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-23 14:01:17.787094: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-23 14:01:17.788372: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-23 14:01:17.789020: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-23 14:01:17.789164: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-23 14:01:17.789247: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-23 14:01:18.246425: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-23 14:01:18.246800: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-23 14:01:18.246894: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-23 14:01:18.246978: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 2631 MB memory:  -> device: 0, name: NVIDIA T600 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8 files belonging to 2 classes.\n",
      "Found 7 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "PATH_TO_DATASET =\"/workspaces/projet_bees_detection_basile/bees_detection/src/datafiles/final_datafiles/dataset_yolo_cropped_with_cleaned_structure.csv\"\n",
    "\n",
    "##### PARAMETERS #####\n",
    "OUTPUT_FOLDER = \"/workspaces/projet_bees_detection_basile/data_bees_detection/benchmark_classification/23_05_VGG16\"\n",
    "IMG_SIZE = 224\n",
    "CAP = 20000\n",
    "NB_IMG_TO_KEEP = 20\n",
    "##### PARAMETERS #####\n",
    "\n",
    "train_dataset, val_dataset, test_dataset = create_datasets_and_directories(PATH_TO_DATASET, OUTPUT_FOLDER, cap=CAP, nb_img_to_keep=NB_IMG_TO_KEEP, image_size=IMG_SIZE, only_species=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min : 0.0, max : 255.0, mean : 89.81210327148438, std : 71.43992614746094\n"
     ]
    }
   ],
   "source": [
    "# check one image\n",
    "test = train_dataset.as_numpy_iterator()\n",
    "image, label = next(test)\n",
    "\n",
    "min,max,mean,std = np.min(image), np.max(image), np.mean(image), np.std(image)\n",
    "\n",
    "print(\"min : {}, max : {}, mean : {}, std : {}\".format(min,max,mean,std))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "NB_CLASSES = len(train_dataset.class_names)\n",
    "CLASS_NAMES = train_dataset.class_names"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PROCESS INPUTS\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def color_preprocessing(x):\n",
    "    x = x.astype('float32')\n",
    "\n",
    "    # RGB \n",
    "    mean = [125.3, 123.0, 113.9]\n",
    "    std  = [63.0,  62.1,  66.7]\n",
    "\n",
    "\n",
    "    # TODO : modify fo imagenet mean = [0.485, 0.456, 0.406] and std = [0.229, 0.224, 0.225]\".\n",
    "\n",
    "    for i in range(3):\n",
    "        # standardization\n",
    "        x[:,:,:,i] = (x[:,:,:,i] - mean[i]) / std[i]\n",
    "    return x\n",
    "     \n",
    "\n",
    "from keras.utils import Sequence\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "\n",
    "class AbeillesSequence(Sequence):\n",
    "    # Initialisation de la séquence avec différents paramètres\n",
    "\n",
    "    def __init__(self, x_train, y_train, batch_size, augmentations,class_names):\n",
    "        self.x_train = x_train\n",
    "        self.y_train = y_train\n",
    "        self.classes = class_names\n",
    "        self.batch_size = batch_size\n",
    "        self.augment = augmentations\n",
    "        self.indices1 = np.arange(len(x_train))\n",
    "\n",
    "\n",
    "        np.random.shuffle(self.indices1) \n",
    "        # Les indices permettent d'accéder\n",
    "        # aux données et sont randomisés à chaque epoch pour varier la composition\n",
    "        # des batches au cours de l'entraînement\n",
    "\n",
    "    # Fonction calculant le nombre de pas de descente du gradient par epoch\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(x_train.shape[0] / float(self.batch_size)))\n",
    "    \n",
    "    def _read_img(self, img_path):\n",
    "        img = cv.imread(img_path)\n",
    "        img = cv.cvtColor(img, cv.COLOR_BGR2RGB)\n",
    "        return img\n",
    "\n",
    "\n",
    "    # Fonction appelée à chaque nouveau batch : sélection et augmentation des données\n",
    "    # idx = position du batch (idx = 5 => on prend le 5ème batch)\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        # Sélection des données\n",
    "        batch_x = self.x_train[self.indices1[idx * self.batch_size:(idx + 1) * self.batch_size]]\n",
    "        batch_y = self.y_train[self.indices1[idx * self.batch_size:(idx + 1) * self.batch_size]]\n",
    "           \n",
    "        # Lecture des images\n",
    "        batch_x = np.array([self._read_img(file_name) for file_name in batch_x])\n",
    "\n",
    "        # Normalisation des données\n",
    "        batch_x = color_preprocessing(batch_x)\n",
    "        \n",
    "        return batch_x, batch_y\n",
    "\n",
    "    # Fonction appelée à la fin d'un epoch ; on randomise les indices d'accès aux données\n",
    "    def on_epoch_end(self):\n",
    "        np.random.shuffle(self.indices1)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_datasets(train_dataset,test_dataset,val_dataset):\n",
    "  \"\"\"\n",
    "  Given three BatchDatasets objects, process them to have inputable objects.\n",
    "\n",
    "  args : \n",
    "      - train_dataset\n",
    "      - test_dataset\n",
    "      - val_dataset\n",
    "  \n",
    "  returns :\n",
    "      - ds_train : abeilleSequence ojbect\n",
    "      - x_val,y_val : np arrays\n",
    "      - x_test,y_test : np arrays\n",
    "      - \n",
    "  \"\"\"\n",
    "\n",
    "\n",
    "  #### TRAIN ####\n",
    "\n",
    "  x_train = np.array(train_dataset.file_paths)\n",
    "  y_train = np.zeros((len(train_dataset.file_paths),NB_CLASSES))\n",
    "\n",
    "  ind_data = 0\n",
    "  for bx, by in train_dataset.as_numpy_iterator():\n",
    "    y_train[ind_data:ind_data+bx.shape[0]] = by\n",
    "    ind_data += bx.shape[0]\n",
    "\n",
    "\n",
    "  ds_train = AbeillesSequence(x_train, y_train, batch_size=32, augmentations=None, class_names=CLASS_NAMES)\n",
    "\n",
    "  #### VAL ####\n",
    "\n",
    "  # Normalisation des données de validation\n",
    "  x_val = np.zeros((len(val_dataset.file_paths),IMG_SIZE,IMG_SIZE,3))\n",
    "  y_val = np.zeros((len(val_dataset.file_paths), len(val_dataset.class_names)))\n",
    "\n",
    "  ind_data = 0\n",
    "  for bx, by in val_dataset.as_numpy_iterator():\n",
    "    x_val[ind_data:ind_data+bx.shape[0]] = bx\n",
    "    y_val[ind_data:ind_data+bx.shape[0]] = by\n",
    "    ind_data += bx.shape[0]\n",
    "\n",
    "  x_val = color_preprocessing(x_val)\n",
    "\n",
    "\n",
    "  #### TEST ####\n",
    "  x_test = np.zeros((len(test_dataset.file_paths),IMG_SIZE,IMG_SIZE,3 ))\n",
    "  y_test = np.zeros((len(test_dataset.file_paths), len(test_dataset.class_names)))\n",
    "\n",
    "  ind_data = 0\n",
    "\n",
    "  for bx, by in test_dataset.as_numpy_iterator():\n",
    "    x_test[ind_data:ind_data+bx.shape[0]] = bx\n",
    "    y_test[ind_data:ind_data+bx.shape[0]] = by\n",
    "    ind_data += bx.shape[0]\n",
    "\n",
    "  x_test= color_preprocessing(x_test)\n",
    "\n",
    "\n",
    "  return ds_train , x_val , y_val , x_test , y_test\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CONSTRUCT MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "base_model = tf.keras.applications.ResNet50(input_shape=(IMG_SIZE,IMG_SIZE,3), include_top=False, weights='imagenet')\n",
    "\n",
    "base_model.trainable = False\n",
    "\n",
    "flatten = tf.keras.layers.Flatten()(base_model.output)\n",
    "dense_1 = tf.keras.layers.Dense(256, activation='relu')(flatten)\n",
    "dense_2 = tf.keras.layers.Dense(128, activation='relu')(dense_1)\n",
    "classification = tf.keras.layers.Dense(NB_CLASSES, activation='softmax')(dense_2)\n",
    "\n",
    "model = tf.keras.models.Model(inputs=base_model.input, outputs=classification)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_bees",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
