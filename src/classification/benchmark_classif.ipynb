{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-25 19:37:54.254226: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-25 19:37:54.393413: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-05-25 19:37:54.984213: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-05-25 19:37:54.984288: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-05-25 19:37:54.984293: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils import image_dataset_from_directory"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. UTILS"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CREATE DATASETS AND PROPER FOLDER STUCTURE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_datasets_and_directories(path_to_csv,path_to_output,cap,nb_img_to_keep,only_species=True,image_size=128):\n",
    "\n",
    "    \"\"\"\n",
    "    Given a dataset of cropped images, create the train, validation and test folders.\n",
    "    Only keeps the images with more than cap images in the dataset, keeps only nb_img_to_keep images per class.\n",
    "    Split for train, validation and test is 80/10/10.\n",
    "    \n",
    "    args : \n",
    "\n",
    "    path_to_csv : path to the csv file containing the dataset\n",
    "                    # paths , # labels \n",
    "    path_to_output : path to the output folder were folders will be created\n",
    "                     in this format : \n",
    "                        output_folder\n",
    "                            - train\n",
    "                            - validation\n",
    "                            - test\n",
    "                            - train_dataset.csv\n",
    "                            - validation_dataset.csv\n",
    "                            - test_dataset.csv\n",
    "                            - weights.h5\n",
    "    cap : minimum number of images per class, if None no cap\n",
    "    nb_img_to_keep : number of images to keep per class, if None keep all images\n",
    "    only_species : if True, only keeps the images labelled as species (i.e. real labels has more than 1 word) \n",
    "                     if False, keeps all the images\n",
    "    image_size : size of the images to resize to\n",
    "    TODO : integrate the only_species = False\n",
    "    \n",
    "    Returns : \n",
    "        train_dataset, validation_dataset, test_dataset : Dataset objects\n",
    "    \"\"\"\n",
    "\n",
    "    ###### FILTER THE DATASET ######\n",
    "\n",
    "    # read the csv file\n",
    "    df_dataset = pd.read_csv(path_to_csv)\n",
    "    \n",
    "    # Take only the images labelled as species (i.e. real labels has more than 1 word)\n",
    "    if only_species:\n",
    "        df_dataset = df_dataset[df_dataset[\"Labels\"].str.contains(\" \")]\n",
    "  \n",
    "    # Get the number of species that have more than cap images\n",
    "    if cap is not None : \n",
    "        species = df_dataset['Labels'].value_counts()[df_dataset['Labels'].value_counts() > cap]\n",
    "\n",
    "        # Convert the series to a dataframe\n",
    "        species = species.to_frame()\n",
    "\n",
    "        # Reset the index\n",
    "        species.reset_index(inplace=True)\n",
    "\n",
    "        # Rename the columns\n",
    "        species.columns = ['Species', 'Number of images']\n",
    "\n",
    "        # Filter the dataset\n",
    "        df_dataset = df_dataset[df_dataset[\"Labels\"].isin(species[\"Species\"])]\n",
    "\n",
    "        print(\"Number of species with more than {} images : {}\".format(cap, len(species)))\n",
    "        print(\"Number of images in the filtered dataset : {}\".format(len(df_dataset)))\n",
    "\n",
    "        print('-'*50)\n",
    "\n",
    "        print(df_dataset['Labels'].value_counts())\n",
    "\n",
    "    if nb_img_to_keep is not None : \n",
    "        \n",
    "        dataset = df_dataset.groupby('Labels').head(nb_img_to_keep)\n",
    "\n",
    "    #### SPLITS THE DATASET #####\n",
    "\n",
    "\n",
    "    # Get the paths and the labels\n",
    "    X = dataset[\"Paths\"]\n",
    "    y = dataset[\"Labels\"]\n",
    "\n",
    "    \n",
    "    X_train, X_test_val, y_train, y_test_val = train_test_split(X, y, test_size=0.3, stratify=y, random_state=42)\n",
    "    X_test, X_val, y_test, y_val = train_test_split(X_test_val, y_test_val, test_size=0.5, stratify=y_test_val, random_state=42)\n",
    "\n",
    "    # Create the train, validation and test datasets\n",
    "\n",
    "    train_dataset = pd.concat([X_train, y_train], axis=1)\n",
    "    val_dataset = pd.concat([X_val, y_val], axis=1)\n",
    "    test_dataset = pd.concat([X_test, y_test], axis=1)\n",
    "\n",
    "\n",
    "    # # Making sure that each label is present in the train, validation and test sets\n",
    "\n",
    "    # train_dataset = dataset.sample(frac=0.8, random_state=0)\n",
    "    # test_dataset = dataset.drop(train_dataset.index)\n",
    "\n",
    "    # train_dataset = train_dataset.reset_index(drop=True)\n",
    "    # test_dataset = test_dataset.reset_index(drop=True)\n",
    "\n",
    "    # train_dataset, val_dataset = train_test_split(train_dataset, test_size=0.2, random_state=0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    ###### CREATE THE FOLDER STRUCTURE ######\n",
    "\n",
    "    if os.path.exists(path_to_output):\n",
    "        shutil.rmtree(path_to_output)\n",
    "\n",
    "    os.makedirs(path_to_output)\n",
    "\n",
    "    os.makedirs(path_to_output + \"/train\")\n",
    "    os.makedirs(path_to_output + \"/validation\")\n",
    "    os.makedirs(path_to_output + \"/test\")\n",
    "\n",
    "    ###### COPY THE IMAGES TO THE FOLDERS ######\n",
    "\n",
    "    for index, row in train_dataset.iterrows():\n",
    "\n",
    "        # Create the folder if it does not exist\n",
    "        if not os.path.exists(path_to_output + \"/train/\" + row[\"Labels\"]):\n",
    "            os.makedirs(path_to_output + \"/train/\" + row[\"Labels\"])\n",
    "\n",
    "        # Copy the image\n",
    "        shutil.copy(row[\"Paths\"], path_to_output + \"/train/\" + row[\"Labels\"])\n",
    "\n",
    "    for index, row in val_dataset.iterrows():\n",
    "            \n",
    "            # Create the folder if it does not exist\n",
    "            if not os.path.exists(path_to_output + \"/validation/\" + row[\"Labels\"]):\n",
    "                os.makedirs(path_to_output + \"/validation/\" + row[\"Labels\"])\n",
    "    \n",
    "            # Copy the image\n",
    "            shutil.copy(row[\"Paths\"], path_to_output + \"/validation/\" + row[\"Labels\"])\n",
    "\n",
    "    for index, row in test_dataset.iterrows():\n",
    "\n",
    "        # Create the folder if it does not exist\n",
    "        if not os.path.exists(path_to_output + \"/test/\" + row[\"Labels\"]):\n",
    "            os.makedirs(path_to_output + \"/test/\" + row[\"Labels\"])\n",
    "\n",
    "        # Copy the image\n",
    "        shutil.copy(row[\"Paths\"], path_to_output + \"/test/\" + row[\"Labels\"])\n",
    "\n",
    "    ###### CREATE THE CSV FILES ######\n",
    "\n",
    "    train_dataset.to_csv(path_to_output + \"/train_dataset.csv\", index=False)\n",
    "    val_dataset.to_csv(path_to_output + \"/validation_dataset.csv\", index=False)\n",
    "    test_dataset.to_csv(path_to_output + \"/test_dataset.csv\", index=False)\n",
    "\n",
    "\n",
    "    ##### MAKE THE DATASET OBJECTS #####\n",
    "\n",
    "    train_dataset = image_dataset_from_directory(os.path.join(path_to_output,\"train\"), shuffle=True, batch_size=32, image_size=(image_size,image_size),labels = 'inferred',label_mode= 'categorical')\n",
    "    test_dataset = image_dataset_from_directory(os.path.join(path_to_output,\"test\"), shuffle=True, batch_size=32, image_size=(image_size,image_size),labels = 'inferred',label_mode= 'categorical')\n",
    "    val_dataset = image_dataset_from_directory(os.path.join(path_to_output,\"validation\" ),shuffle=True, batch_size=32, image_size=(image_size,image_size),labels = 'inferred',label_mode= 'categorical')\n",
    "\n",
    "    ##### PRINT INFO #####\n",
    "\n",
    "    print('-'*50)\n",
    "    print('-'*50)\n",
    "\n",
    "    print(\"Number of species in the train dataset : {}\".format(len(train_dataset.class_names)))\n",
    "    print(\"Number of images in the train dataset : {}\".format(len(train_dataset.file_paths)))\n",
    "\n",
    "    print('-'*50)\n",
    "    print(\"Number of species in the validation dataset : {}\".format(len(val_dataset.class_names)))\n",
    "    print(\"Number of images in the validation dataset : {}\".format(len(val_dataset.file_paths)))\n",
    "    \n",
    "    print('-'*50)\n",
    "    print(\"Number of species in the test dataset : {}\".format(len(test_dataset.class_names)))\n",
    "    print(\"Number of images in the test dataset : {}\".format(len(test_dataset.file_paths)))\n",
    "\n",
    "    print('-'*50)\n",
    "    print('-'*50)\n",
    "\n",
    "\n",
    "    \n",
    "    return train_dataset, val_dataset, test_dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PROCESS INPUTS\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def color_preprocessing(x):\n",
    "    x = x.astype('float32')\n",
    "\n",
    "    # RGB \n",
    "    mean = [125.3, 123.0, 113.9]\n",
    "    std  = [63.0,  62.1,  66.7]\n",
    "\n",
    "\n",
    "    # TODO : modify fo imagenet mean = [0.485, 0.456, 0.406] and std = [0.229, 0.224, 0.225]\".\n",
    "\n",
    "    for i in range(3):\n",
    "        # standardization\n",
    "        x[:,:,:,i] = (x[:,:,:,i] - mean[i]) / std[i]\n",
    "    return x\n",
    "     \n",
    "\n",
    "from keras.utils import Sequence\n",
    "import numpy as np\n",
    "import cv2 as cv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AbeillesSequence(Sequence):\n",
    "    #  Initialisation de la séquence avec différents paramètres\n",
    "    def __init__(self, x_train, y_train, batch_size, class_names, image_size):\n",
    "        self.x_train = x_train\n",
    "        self.y_train = y_train\n",
    "        self.classes = class_names\n",
    "        self.batch_size = batch_size\n",
    "        self.image_size = image_size\n",
    "        self.indices1 = np.arange(len(x_train))\n",
    "\n",
    "        np.random.shuffle(self.indices1)\n",
    "        #  Les indices permettent d'accéder\n",
    "        #  aux données et sont randomisés à chaque epoch pour varier la composition\n",
    "        #  des batches au cours de l'entraînement\n",
    "\n",
    "    #  Fonction calculant le nombre de pas de descente du gradient par epoch\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(self.x_train.shape[0] / float(self.batch_size)))\n",
    "\n",
    "    # Application de l'augmentation de données à chaque image du batch\n",
    "\n",
    "    def apply_augmentation(self, bx, by):\n",
    "\n",
    "        batch_x = np.zeros((bx.shape[0], self.image_size, self.image_size, 3))\n",
    "        batch_y = by\n",
    "\n",
    "        # Pour chaque image du batch\n",
    "        for i in range(len(bx)):\n",
    "\n",
    "            # Récupération du label de l'image\n",
    "            class_labels = []\n",
    "            class_id = np.argmax(by[i])\n",
    "            class_labels.append(self.classes[class_id])\n",
    "\n",
    "            # Read image\n",
    "            img = cv.imread(bx[i])\n",
    "            img = cv.cvtColor(img, cv.COLOR_BGR2RGB)\n",
    "\n",
    "            # resize\n",
    "            img = self._resize_img_(img)\n",
    "\n",
    "            batch_x[i] = img\n",
    "\n",
    "        return batch_x, batch_y\n",
    "\n",
    "    def _resize_img_(self, img):\n",
    "        # resize img to image_size x image_size, add padding if necessary\n",
    "\n",
    "        shape = img.shape\n",
    "\n",
    "        # cas 1 : both dimensions are too small\n",
    "        if shape[0] < self.image_size and shape[1] < self.image_size:\n",
    "\n",
    "            # add padding\n",
    "            img = cv.copyMakeBorder(\n",
    "                img, 0, self.image_size - shape[0], 0, self.image_size - shape[1], cv.BORDER_CONSTANT, value=0)\n",
    "\n",
    "        # cas 2 : every other case\n",
    "        else:\n",
    "\n",
    "            # add padding to the smallest dimension to make it equal to the biggest one\n",
    "            if shape[0] < shape[1]:\n",
    "                img = cv.copyMakeBorder(\n",
    "                    img, 0, shape[1] - shape[0], 0, 0, cv.BORDER_CONSTANT, value=0)\n",
    "            else:\n",
    "                img = cv.copyMakeBorder(\n",
    "                    img, 0, 0, 0, shape[0] - shape[1], cv.BORDER_CONSTANT, value=0)\n",
    "\n",
    "            # resize\n",
    "            img = cv.resize(img, (self.image_size, self.image_size))\n",
    "\n",
    "        return img\n",
    "\n",
    "    #  Fonction appelée à chaque nouveau batch : sélection et augmentation des données\n",
    "    # idx = position du batch (idx = 5 => on prend le 5ème batch)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Sélection des données : batch x correspond aux filepath\n",
    "        batch_x = self.x_train[self.indices1[idx *\n",
    "                                             self.batch_size:(idx + 1) * self.batch_size]]\n",
    "        batch_y = self.y_train[self.indices1[idx *\n",
    "                                             self.batch_size:(idx + 1) * self.batch_size]]\n",
    "\n",
    "        #  Application de l'augmentation de données\n",
    "        batch_x, batch_y = self.apply_augmentation(batch_x, batch_y)\n",
    "\n",
    "        # Normalisation des données\n",
    "        batch_x = color_preprocessing(batch_x)\n",
    "\n",
    "        #### temp ####\n",
    "\n",
    "        mean, std, min, max = np.mean(batch_x), np.std(\n",
    "            batch_x), np.min(batch_x), np.max(batch_x)\n",
    "        shp = batch_x.shape\n",
    "\n",
    "        print('-'*50)\n",
    "        print(\"mean : {}\".format(mean), \"std : {}\".format(std),\n",
    "              \"min : {}\".format(min), \"max : {}\".format(max))\n",
    "        \n",
    "\n",
    "        return batch_x, batch_y\n",
    "\n",
    "    #  Fonction appelée à la fin d'un epoch ; on randomise les indices d'accès aux données\n",
    "    def on_epoch_end(self):\n",
    "        np.random.shuffle(self.indices1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_datasets(train_dataset,test_dataset,val_dataset,img_size,batch_size):\n",
    "  \"\"\"\n",
    "  Given three BatchDatasets objects, process them to have inputable objects.\n",
    "\n",
    "  args : \n",
    "      - train_dataset\n",
    "      - test_dataset\n",
    "      - val_dataset\n",
    "  \n",
    "  returns :\n",
    "      - ds_train : abeilleSequence ojbect\n",
    "      - x_val,y_val : np arrays\n",
    "      - x_test,y_test : np arrays\n",
    "      - \n",
    "  \"\"\"\n",
    "\n",
    "\n",
    "  #### TRAIN ####\n",
    "\n",
    "  x_train = np.array(train_dataset.file_paths)\n",
    "  y_train = np.zeros((len(train_dataset.file_paths), len(train_dataset.class_names)))\n",
    "\n",
    "  ind_data = 0\n",
    "  for bx, by in train_dataset.as_numpy_iterator():\n",
    "    y_train[ind_data:ind_data+bx.shape[0]] = by\n",
    "    ind_data += bx.shape[0]\n",
    "\n",
    "\n",
    "  ds_train = AbeillesSequence(x_train, y_train, batch_size=batch_size, class_names=train_dataset.class_names,image_size=img_size)\n",
    "\n",
    "  #### VAL ####\n",
    "\n",
    "  # Normalisation des données de validation\n",
    "  x_val = np.zeros((len(val_dataset.file_paths),img_size,img_size,3))\n",
    "  x_val_temp = np.array(val_dataset.file_paths)\n",
    "  y_val = np.zeros((len(val_dataset.file_paths), len(val_dataset.class_names)))\n",
    "\n",
    "  ind_data = 0\n",
    "  for bx, by in val_dataset.as_numpy_iterator():\n",
    "    x_val[ind_data:ind_data+bx.shape[0]] = bx\n",
    "    y_val[ind_data:ind_data+bx.shape[0]] = by\n",
    "    ind_data += bx.shape[0]\n",
    "\n",
    "  x_val = color_preprocessing(x_val)\n",
    "\n",
    "  ds_val = AbeillesSequence(x_val_temp, y_val, batch_size=batch_size, class_names=val_dataset.class_names,image_size=img_size)\n",
    "\n",
    "\n",
    "  #### TEST ####\n",
    "  x_test = np.zeros((len(test_dataset.file_paths),img_size,img_size,3 ))\n",
    "  y_test = np.zeros((len(test_dataset.file_paths), len(test_dataset.class_names)))\n",
    "\n",
    "  ind_data = 0\n",
    "\n",
    "  for bx, by in test_dataset.as_numpy_iterator():\n",
    "    x_test[ind_data:ind_data+bx.shape[0]] = bx\n",
    "    y_test[ind_data:ind_data+bx.shape[0]] = by\n",
    "    ind_data += bx.shape[0]\n",
    "\n",
    "  x_test= color_preprocessing(x_test)\n",
    "\n",
    "\n",
    "  return ds_train , x_val , y_val , x_test , y_test, ds_val\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PLOT HISTORY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def plot_history(history,path):\n",
    "\n",
    "    plt.figure(figsize=(20,10))\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.plot(history.history['categorical_accuracy'])\n",
    "    plt.plot(history.history['val_categorical_accuracy'])\n",
    "    plt.title('Accuracy')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['train', 'val'], loc='upper left')\n",
    "\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('Loss')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['train', 'val'], loc='upper left')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    plt.savefig(path)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. BENCHMARK MODELS\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple VGG16 no callbacks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of species with more than 20000 images : 2\n",
      "Number of images in the filtered dataset : 69628\n",
      "--------------------------------------------------\n",
      "Apis mellifera       49093\n",
      "Bombus terrestris    20535\n",
      "Name: Labels, dtype: int64\n",
      "Found 1400 files belonging to 2 classes.\n",
      "Found 300 files belonging to 2 classes.\n",
      "Found 300 files belonging to 2 classes.\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "Number of species in the train dataset : 2\n",
      "Number of images in the train dataset : 1400\n",
      "--------------------------------------------------\n",
      "Number of species in the validation dataset : 2\n",
      "Number of images in the validation dataset : 300\n",
      "--------------------------------------------------\n",
      "Number of species in the test dataset : 2\n",
      "Number of images in the test dataset : 300\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "##### PARAMETERS #####\n",
    "PATH_TO_DATASET =\"/home/basile/Documents/projet_bees_detection_basile/bees_detection/src/datafiles/final_datafiles/dataset_yolo_cropped_with_cleaned_structure.csv\"\n",
    "OUTPUT_FOLDER = \"/home/basile/Documents/projet_bees_detection_basile/data_bees_detection/benchmark_classification/2_Resnet_1000_imgs_2_species_256/\"\n",
    "IMG_SIZE = 256\n",
    "CAP = 20000\n",
    "NB_IMG_TO_KEEP = 1000\n",
    "BACTH_SIZE = 32\n",
    "##### PARAMETERS #####\n",
    "\n",
    "# Create datasets and directories\n",
    "train_dataset, val_dataset, test_dataset = create_datasets_and_directories(PATH_TO_DATASET, OUTPUT_FOLDER, cap=CAP, nb_img_to_keep=NB_IMG_TO_KEEP, image_size=IMG_SIZE, only_species=True)\n",
    "\n",
    "NB_CLASSES = len(train_dataset.class_names)\n",
    "CLASS_NAMES = train_dataset.class_names\n",
    "\n",
    "\n",
    "# Process datasets\n",
    "ds_train , x_val , y_val , x_test , y_test ,ds_val= process_datasets(train_dataset,test_dataset,val_dataset,IMG_SIZE,BACTH_SIZE)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we'll not use "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model \n",
    "\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.layers import Flatten, Dense\n",
    "from keras.models import Model\n",
    "\n",
    "vgg_model = VGG16(weights='imagenet', include_top=False, input_shape=(IMG_SIZE, IMG_SIZE, 3))\n",
    "\n",
    "# FREEZE LAYERS\n",
    "for layer in vgg_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Classification\n",
    "x = vgg_model.output\n",
    "x = Flatten()(x)\n",
    "x = Dense(512, activation=\"relu\")(x)\n",
    "x = Dense(NB_CLASSES, activation=\"softmax\")(x)\n",
    "\n",
    "model = Model(inputs=vgg_model.input, outputs=x)\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_bees",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
